{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **XGBoost**\n",
    "\n",
    "### Group Name: BYD2060\n",
    "\n",
    "### Link to the github repo: https://github.com/Yangxinyee/XGboost_for_BYD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost, or Extreme Gradient Boosting, is an efficient, scalable machine learning algorithm used primarily for supervised learning tasks like classification and regression. It builds upon gradient boosting principles to create an ensemble of weak learners that sequentially correct the errors of previous models to improve accuracy.\n",
    "\n",
    "## How XGBoost Works\n",
    "\n",
    "1. **Initialization**:\n",
    "   - Starts with an initial prediction (average value for regression or a default probability for classification).\n",
    "\n",
    "2. **Iterative Model Training**:\n",
    "   - In each step, a new weak learner (we are using decision tree) is trained to minimize residual errors from previous models. \n",
    "   - The weak learner is trained on a modified dataset where the target is now the residual error from the last iteration.\n",
    "\n",
    "3. **Gradient Boosting with Regularization**:\n",
    "   \n",
    "   - XGBoost includes regularization terms in the objective function to control overfitting:\n",
    "     $$\n",
    "     \\text{Objective} = \\sum_{i=1}^{n} L(y_i, \\hat{y}_i) + \\sum_{k=1}^{K} \\Omega(f_k)\n",
    "     $$\n",
    "     where $L(y_i, \\hat{y}_i)$ is the loss function, $\\Omega(f_k)$ is the regularization term for tree $f_k$, $n$ is the numble of samples, and $k$ is the number of trees (Chen & Guestrin, 2016). \n",
    "   \n",
    "4. **Shrinking (Learning Rate)**:\n",
    "   - Applies a learning rate to scale each weak learner’s contribution, ensuring gradual model improvement to prevent overfitting.\n",
    "   \n",
    "5. **Tree Pruning**:\n",
    "   - Uses constraints like \"max depth\" to limit tree depth, preventing overfitting.\n",
    "   \n",
    "6. **Weighted Data and Column Sampling**:\n",
    "   - Row and column sampling prevent overfitting, making the model more robust to noisy data.\n",
    "   \n",
    "7. **Final Prediction**:\n",
    "   - Predictions are generated by aggregating the outputs of all weak learners, often by summing their outputs.\n",
    "\n",
    "## Advantages of XGBoost\n",
    "\n",
    "1. **Highly Efficient and Scalable**:\n",
    "   - Optimized for speed, utilizing CPU/GPU resources for large datasets.\n",
    "\n",
    "2. **Regularization**:\n",
    "   - L1 and L2 regularization helps reduce overfitting, improving generalization (Friedman, 2001).\n",
    "\n",
    "3. **Custom Loss Functions**:\n",
    "   - Allows custom loss functions, adapting well to various tasks and metrics.\n",
    "\n",
    "4. **Handles Missing Values**:\n",
    "   - Automatically learns the best direction for missing values during training.\n",
    "\n",
    "5. **Parallel and Distributed Computing**:\n",
    "   - Supports parallel tree boosting, and distributed training, making it suitable for very large datasets.\n",
    "\n",
    "6. **Feature Importance and Interpretability**:\n",
    "   - Provides feature importance scores for insight into feature contributions.\n",
    "\n",
    "## Disadvantages of XGBoost\n",
    "\n",
    "1. **Complexity in Tuning**:\n",
    "   - Many hyperparameters require tuning; poor parameter settings may lead to suboptimal performance.\n",
    "\n",
    "2. **Sensitive to Noise**:\n",
    "   - Can overfit noisy data or when trees are too deep, despite regularization.\n",
    "\n",
    "3. **High Memory Consumption**:\n",
    "   - Memory-intensive on large datasets with high-dimensional data.\n",
    "\n",
    "4. **Not Ideal for Small Datasets**:\n",
    "   - On small datasets, simpler models may perform better with fewer resources.\n",
    "\n",
    "5. **Black-box Nature**:\n",
    "   - Though feature importance scores provide some interpretability, XGBoost can still be difficult to fully interpret.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of XGBoost\n",
    "\n",
    "In XGBoost with Decision Tree as the weak learner, predictions are made by combining the outputs of a sequence of decision trees. Here’s how XGBoost generates a single prediction from feature values:\n",
    "\n",
    "1. **Initialization**:\n",
    "\n",
    "   - The model starts with an initial prediction for all samples, often set to zero or the average target value if it's a regression task. Let's denote this initial prediction as $F^{(0)}(x)$.\n",
    "\n",
    "2. **Training Decision Trees**:\n",
    "\n",
    "   - In each boosting round $t$, a new Decision Tree $f_t(x)$ is trained to predict the residuals (the difference between the true values $y_i$ and the current predictions $F^{(t-1)}(x_i)$.\n",
    "   - At each split, the Decision Tree splits the data based on a single feature and threshold, recursively creating a set of rules. The final prediction for each sample is determined by the leaf node it falls into after traversing the tree.\n",
    "\n",
    "3. **Tree Prediction**:\n",
    "\n",
    "   - For a feature $x$ and a threshold $\\theta$, a single split in the Decision Tree assigns predictions to samples based on the threshold: \n",
    "     $$\n",
    "     f_t(x) = \\begin{cases} \n",
    "           y_{\\text{left}} & \\text{if } x_i < \\theta \\\\\n",
    "           y_{\\text{right}} & \\text{otherwise}\n",
    "        \\end{cases}\n",
    "     $$\n",
    "\n",
    "   - Here, $y_{\\text{left}}$ and $y_{\\text{right}}$ represent the predicted values for the samples on each side of the split. These predictions are often chosen to minimize the overall error in the objective function (Hastie, Tibshirani & Friedman, 2009).\n",
    "\n",
    "4. **Updating the Overall Prediction**:\n",
    "\n",
    "   - The model’s prediction is updated by adding a scaled version of the Decision Tree’s prediction. The learning rate $\\eta$ controls how much each tree contributes to the final model: \n",
    "     $$\n",
    "     F^{(t)}(x) = F^{(t-1)}(x) + \\eta f_t(x)\n",
    "     $$\n",
    "\n",
    "   - This update means each Decision Tree contributes only a small correction to the existing prediction, allowing the model to make gradual adjustments rather than large changes.\n",
    "\n",
    "5. **Final Prediction**:\n",
    "\n",
    "   - After $T$ boosting rounds, the final prediction for a data point $x$ is the sum of all weak learners' contributions: \n",
    "     $$\n",
    "     F(x) = \\sum_{t=1}^T \\eta f_t(x)\n",
    "     $$\n",
    "\n",
    "   - Each Decision Tree captures patterns by recursively splitting data based on features and thresholds. By combining multiple trees, XGBoost can approximate complex relationships in the data (Chen & Guestrin, 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss of XGBoost\n",
    "\n",
    "The loss is used to measure the error between predicted and actual values. XGBoost supports various loss functions tailored to different types of tasks, including regression and classification tasks.\n",
    "\n",
    "**Loss Function**:\n",
    "\n",
    "For the regression task, we can use Mean Squared Error(MSE) or Mean Absolute Error (MAE) (Hastie, Tibshirani & Friedman, 2009)\n",
    "\n",
    "Mean Squared Error(MSE):\n",
    "$$\n",
    "    L(F^{\\mathbf{(t)}}) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - F^{\\mathbf{(t)}}(\\mathbf{x}_i))^2\n",
    "$$\n",
    "\n",
    "Mean Absolute Error (MAE):\n",
    "$$\n",
    "    L(F^{\\mathbf{(t)}}) = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - F^{\\mathbf{(t)}}(\\mathbf{x}_i)|\n",
    "$$\n",
    "\n",
    "For the binary classification task, we can use Binary Cross Entropy Loss\n",
    "Binary Cross Entropy Loss:\n",
    "\n",
    "$$\n",
    "L_S(F^{\\mathbf{(t)}}) = -\\frac{1}{n} \\sum_{i=1}^{n}\\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - F^{\\mathbf{(t)}}(\\mathbf{x}_i)) \\right]\n",
    "$$\n",
    "\n",
    "For the multiclass classification task, we can use Cross Entropy Loss\n",
    "Cross Entropy Loss (Bishop, 2006):\n",
    "$$\n",
    "    L_S(F^{\\mathbf{(t)}}) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k} \\mathbb{1}[y_i = j] \\log F^{\\mathbf{(t)}}(\\mathbf{x}_i)_j\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $y_i$ is the $i$-th actual value \n",
    "\n",
    "- $n$ is the number of samples \n",
    "\n",
    "- $k$ is the number of classes \n",
    "\n",
    "- $j$ is the $j$-th class \n",
    "\n",
    "- $F^{\\mathbf{(t)}}$ is the model at the $t$-th iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with Decision Tree as Weak Learner: Optimizer Update\n",
    "\n",
    "In this configuration, XGBoost uses a decision tree as the weak learner. The optimizer is updated to account for the decision tree mechanism, which recursively splits the data based on features and thresholds. Each leaf node assigns a constant value to the samples it contains. The prediction update process incorporates a learning rate $\\eta$ to scale the contribution of each tree, ensuring gradual and controlled adjustments to the model (Quinlan, 1996).\n",
    "\n",
    "### Objective Function\n",
    "\n",
    "The objective function consists of the loss and regularization terms:\n",
    "\n",
    "$$\n",
    "\\text{Objective} = \\sum_{i=1}^{n} L(y_i, \\hat{y}_i) + \\sum_{k=1}^{K} \\Omega(f_k)\n",
    "$$\n",
    "\n",
    "where $L(y_i, \\hat{y}_i)$ is the loss function, typically squared error or logistic loss, measuring the difference between the true values $y_i$ and predictions $\\hat{y}_i$. $\\Omega(f_k)$ is the regularization term to control model complexity.\n",
    "\n",
    "At each iteration $t$, the model updates the prediction with the new decision tree’s prediction, scaled by the learning rate $\\eta$:\n",
    "\n",
    "$$\n",
    "F^{(t)}(x) = F^{(t-1)}(x) + \\eta f_t(x)\n",
    "$$\n",
    "\n",
    "where $f_t(x)$ represents the decision tree’s prediction.\n",
    "\n",
    "### Weak Learner\n",
    "\n",
    "For a feature $x$ and a threshold $\\theta$, a single split in the Decision Tree assigns predictions to samples based on the threshold: \n",
    "     $$\n",
    "     f_t(x) = \\begin{cases} \n",
    "           y_{\\text{left}} & \\text{if } x_i < \\theta \\\\\n",
    "           y_{\\text{right}} & \\text{otherwise}\n",
    "        \\end{cases}\n",
    "     $$\n",
    "\n",
    "Here, $y_{\\text{left}}$ and $y_{\\text{right}}$ represent the predicted values for the samples on each side of the split. These predictions are often chosen to minimize the overall error in the objective function.\n",
    "\n",
    "### Approximation with Taylor Expansion\n",
    "\n",
    "To facilitate optimization, we apply a second-order Taylor expansion around the current prediction $F^{(t-1)}$ to approximate the loss function $L(F^{(t)})$:\n",
    "\n",
    "$$\n",
    "L(F^{(t)}) \\approx \\sum_{i=1}^{n} \\left[ L(y_i, F^{(t-1)}(x_i)) + g_i f_t(x_i) + \\frac{1}{2} h_i f_t(x_i)^2 \\right] + \\Omega(f_t)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $g_i = \\frac{\\partial L(y_i, F^{(t-1)}(x_i))}{\\partial F^{(t-1)}(x_i)}$ is the first derivative of the loss with respect to the previous prediction (the gradient).\n",
    "- $h_i = \\frac{\\partial^2 L(y_i, F^{(t-1)}(x_i))}{\\partial F^{(t-1)}(x_i)^2}$ is the second derivative (the Hessian).\n",
    "\n",
    "### Regularization and Optimal Leaf Weights\n",
    "\n",
    "The regularization term for a decision tree $\\Omega(f_t)$ is given by:\n",
    "\n",
    "$$\n",
    "\\Omega(f_t) = \\gamma N + \\frac{1}{2} \\lambda \\sum_{j=1}^{N} w_j^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $N$ is the number of leaf nodes,\n",
    "- $w_j$ is the weight assigned to each leaf, \n",
    "- $\\gamma$ controls the complexity penalty, and $\\lambda$ controls the weight shrinkage.\n",
    "\n",
    "The optimal weight for each leaf $j$ is obtained by minimizing the regularized objective:\n",
    "\n",
    "$$\n",
    "w_j^* = -\\frac{\\sum_{i \\in I_j} g_i}{\\sum_{i \\in I_j} h_i + \\lambda}\n",
    "$$\n",
    "\n",
    "where $I_j$ is the set of sample indices for leaf $j$.\n",
    "\n",
    "### Gain Calculation and Tree Update\n",
    "\n",
    "The gain for adding a new tree, which represents the improvement in the objective function, is:\n",
    "\n",
    "$$\n",
    "\\text{Gain} = \\frac{1}{2} \\sum_{j=1}^{N} \\frac{\\left( \\sum_{i \\in I_j} g_i \\right)^2}{\\sum_{i \\in I_j} h_i + \\lambda} - \\gamma N\n",
    "$$\n",
    "\n",
    "This gain metric helps determine the best split points and decide whether further splitting is beneficial.\n",
    "\n",
    "### Prediction Update\n",
    "\n",
    "Finally, the model’s prediction is updated at each iteration with the contribution from the newly added decision tree:\n",
    "\n",
    "$$\n",
    "F^{(t)}(x) = F^{(t-1)}(x) + \\eta f_t(x)\n",
    "$$\n",
    "\n",
    "where $\\eta$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Pseudo-code\n",
    "\n",
    "**Input**:  \n",
    "- Training set $S = \\{(x_1, y_1), \\ldots, (x_m, y_m)\\}$  \n",
    "- Weak learner $f_t(x)$ (Decision Tree)  \n",
    "- Number of boosting rounds $T$  \n",
    "- Learning rate $\\eta$  \n",
    "- Regularization parameters $\\lambda, \\gamma$  \n",
    "\n",
    "**Initialize**:  \n",
    "$F^{(0)}(x) = 0$  \n",
    "\n",
    "**for** $t = 1, \\ldots, T$:  \n",
    "1. **Compute gradients and Hessians**:  \n",
    "   $g_i = \\frac{\\partial L(y_i, F^{(t-1)}(x_i))}{\\partial F^{(t-1)}(x_i)}$  \n",
    "   $h_i = \\frac{\\partial^2 L(y_i, F^{(t-1)}(x_i))}{\\partial F^{(t-1)}(x_i)^2}$  \n",
    "\n",
    "2. **Find the best split**:  \n",
    "   - For each feature and threshold $\\theta$:  \n",
    "     - Split data into left and right groups based on $\\theta$  \n",
    "     - Compute split gain using gradients and Hessians  \n",
    "   - Select feature and threshold $\\theta$ with the highest gain  \n",
    "\n",
    "3. **Train decision tree** $f_t(x)$:  \n",
    "   - Fit $f_t(x)$ using the selected splits  \n",
    "   - Assign values $y_{\\text{left}}$ and $y_{\\text{right}}$ to leaf nodes  \n",
    "   - Compute optimal weights $w_j$ for each leaf node  \n",
    "\n",
    "4. **Update model**:  \n",
    "   $F^{(t)}(x) = F^{(t-1)}(x) + \\eta f_t(x)$  \n",
    "\n",
    "**Output**:  \n",
    "Final model prediction: $F(x) = F^{(T)}(x)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class DecisionTree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\" \n",
    "    A class representing a decision tree model used in gradient boosting.\n",
    "    Attributes:\n",
    "        max_depth (int): Maximum depth of the tree.\n",
    "        min_samplessplit (int): Minimum number of samples required to split a node.\n",
    "        tree (dict or float): The root of the tree, represented as a dictionary or a leaf value.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=3, min_samplessplit=2):\n",
    "        \"\"\" \n",
    "        Initializes the DecisionTree with maximum depth and minimum samples required to split.\n",
    "        @params:\n",
    "            max_depth (int): The maximum depth of the tree. Default is 3.\n",
    "            min_samplessplit (int): Minimum samples required to split a node. Default is 2.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samplessplit = min_samplessplit\n",
    "        self.tree = None\n",
    "\n",
    "    def train(self, X, y, grad, hess):\n",
    "        \"\"\" \n",
    "        Trains the decision tree using the given data, gradients, and hessians.\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with training data.\n",
    "            y (numpy.ndarray): A 1D array of shape (n_samples,) with target values.\n",
    "            grad (numpy.ndarray): A 1D array of gradients for each sample.\n",
    "            hess (numpy.ndarray): A 1D array of hessians for each sample.\n",
    "        \"\"\"\n",
    "        self.tree = self.build_tree(X, y, grad, hess)\n",
    "\n",
    "    def split(self, X, y, grad, hess):\n",
    "        \"\"\" \n",
    "        Finds the best split for the data to maximize the gain.\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with training data.\n",
    "            y (numpy.ndarray): A 1D array of shape (n_samples,) with target values.\n",
    "            grad (numpy.ndarray): A 1D array of gradients for each sample.\n",
    "            hess (numpy.ndarray): A 1D array of hessians for each sample.\n",
    "        @return:\n",
    "            tuple: The best feature index and threshold for the split.\n",
    "        \"\"\"\n",
    "        best_gain = -np.inf\n",
    "        best_split = None\n",
    "        # Iterate over all features to find the best split point\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            # Sort feature values and compute threshold for splits\n",
    "            sorted_index = np.argsort(X[:, feature_index])\n",
    "            X_sorted, grad_sorted, hess_sorted = X[sorted_index, feature_index], grad[sorted_index], hess[sorted_index]\n",
    "            # Initialize left and right sum of gradients and Hessians\n",
    "            G_L, H_L = 0, 0  \n",
    "            G_R, H_R = np.sum(grad_sorted), np.sum(hess_sorted)\n",
    "\n",
    "            # Iterate over feature values to find the best split point\n",
    "            for i in range(1, len(X_sorted)):\n",
    "                G_L += grad_sorted[i - 1]\n",
    "                H_L += hess_sorted[i - 1]\n",
    "                G_R -= grad_sorted[i - 1]\n",
    "                H_R -= hess_sorted[i - 1]\n",
    "\n",
    "                # Check if the split meets the minimum sample requirement\n",
    "                if i < self.min_samplessplit or len(X_sorted) - i < self.min_samplessplit:\n",
    "                    continue\n",
    "\n",
    "                # Calculate gain for this split using a separate function\n",
    "                gain = self.gain(G_L, H_L, G_R, H_R)\n",
    "                \n",
    "                # Update the best gain and split if the current gain is higher\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split = (feature_index, (X_sorted[i - 1] + X_sorted[i]) / 2)\n",
    "                    \n",
    "        return best_split\n",
    "\n",
    "    def gain(self, G_L, H_L, G_R, H_R):\n",
    "        \"\"\" \n",
    "        Calculates the gain of a split using left and right gradient and Hessian sums.\n",
    "        @params:\n",
    "            G_L (float): Sum of gradients for the left split.\n",
    "            H_L (float): Sum of Hessians for the left split.\n",
    "            G_R (float): Sum of gradients for the right split.\n",
    "            H_R (float): Sum of Hessians for the right split.\n",
    "        @return:\n",
    "            float: The calculated gain for the split.\n",
    "        \"\"\"\n",
    "        # Gain formula using left and right gradient and Hessian sums\n",
    "        gain = 0.5 * ((G_L ** 2) / (H_L + 1e-10) + (G_R ** 2) / (H_R + 1e-10) - ((G_L + G_R) ** 2) / (H_L + H_R + 1e-10))\n",
    "        return gain\n",
    "\n",
    "    def build_tree(self, X, y, grad, hess, depth=0):\n",
    "        \"\"\" \n",
    "        Recursively builds the decision tree based on the provided data.\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with training data.\n",
    "            y (numpy.ndarray): A 1D array of target values.\n",
    "            grad (numpy.ndarray): A 1D array of gradients for each sample.\n",
    "            hess (numpy.ndarray): A 1D array of hessians for each sample.\n",
    "            depth (int): The current depth of the tree.\n",
    "        @return:\n",
    "            dict or float: A dictionary representing the subtree or a leaf value.\n",
    "        \"\"\"\n",
    "        if depth == self.max_depth or len(y) < self.min_samplessplit:\n",
    "            # Return leaf value if maximum depth is reached or samples are insufficient\n",
    "            leaf_value = -np.sum(grad) / (np.sum(hess) + 1e-10)\n",
    "            return leaf_value\n",
    "\n",
    "        best_split = self.split(X, y, grad, hess)\n",
    "        if not best_split:\n",
    "            # Return leaf value if no valid split is found\n",
    "            return -np.sum(grad) / (np.sum(hess) + 1e-10)\n",
    "\n",
    "        feature_index, threshold = best_split\n",
    "        left_mask = X[:, feature_index] < threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        # Recursively build left and right subtrees\n",
    "        left_subtree = self.build_tree(X[left_mask], y[left_mask], grad[left_mask], hess[left_mask], depth + 1)\n",
    "        right_subtree = self.build_tree(X[right_mask], y[right_mask], grad[right_mask], hess[right_mask], depth + 1)\n",
    "        return {\"feature_index\": feature_index, \"threshold\": threshold, \"left\": left_subtree, \"right\": right_subtree}\n",
    "\n",
    "    def predict_single(self, x, tree):\n",
    "        \"\"\" \n",
    "        Predicts the value for a single sample using the decision tree.\n",
    "        @params:\n",
    "            x (numpy.ndarray): A 1D array of feature values for a single sample.\n",
    "            tree (dict or float): The decision tree or leaf value to predict with.\n",
    "        @return:\n",
    "            float: The predicted value for the sample.\n",
    "        \"\"\"\n",
    "        if not isinstance(tree, dict):\n",
    "            # Return the leaf value if the node is a leaf\n",
    "            return tree\n",
    "\n",
    "        feature_index = tree[\"feature_index\"]\n",
    "        threshold = tree[\"threshold\"]\n",
    "        # Traverse left or right subtree based on the feature value\n",
    "        if x[feature_index] < threshold:\n",
    "            return self.predict_single(x, tree[\"left\"])\n",
    "        else:\n",
    "            return self.predict_single(x, tree[\"right\"])\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" \n",
    "        Predicts the values for multiple samples using the decision tree.\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with input data.\n",
    "        @return:\n",
    "            numpy.ndarray: A 1D array of predicted values for each sample.\n",
    "        \"\"\"\n",
    "        return np.array([self.predict_single(x, self.tree) for x in X])\n",
    "\n",
    "    def print_tree(self, tree=None, node_id=0, depth=0):\n",
    "        \"\"\" \n",
    "        Prints the structure of the decision tree with node IDs.\n",
    "        \"\"\"\n",
    "        if tree is None:\n",
    "            tree = self.tree\n",
    "\n",
    "        # initialize queue and node number\n",
    "        queue = [(tree, 0)]\n",
    "        node_map = {}\n",
    "        node_counter = 0 \n",
    "\n",
    "        # number the nodes in breadth-first order\n",
    "        while queue:\n",
    "            node, parent_id = queue.pop(0)\n",
    "            node_id = node_counter\n",
    "            node_map[id(node)] = node_id\n",
    "            node_counter += 1\n",
    "            if isinstance(node, dict):\n",
    "                queue.append((node[\"left\"], node_id))\n",
    "                queue.append((node[\"right\"], node_id))\n",
    "\n",
    "        # print node in depth-first order\n",
    "        def depth_first_traversal(node, depth):\n",
    "            node_id = node_map[id(node)]\n",
    "            if isinstance(node, dict):\n",
    "                # print current split node\n",
    "                feature_index = node[\"feature_index\"]\n",
    "                threshold = node[\"threshold\"]\n",
    "                left_id = node_map[id(node[\"left\"])]\n",
    "                right_id = node_map[id(node[\"right\"])]\n",
    "                print(\n",
    "                    \"\\t\" * depth\n",
    "                    + f\"{node_id}:[f{feature_index}<{threshold:.6f}] yes={left_id},no={right_id},missing={right_id}\"\n",
    "                )\n",
    "                # print left and right sub-tree recursively\n",
    "                depth_first_traversal(node[\"left\"], depth + 1)\n",
    "                depth_first_traversal(node[\"right\"], depth + 1)\n",
    "            else:\n",
    "                # leaf node\n",
    "                print(\"\\t\" * depth + f\"{node_id}:leaf={node:.6f}\")\n",
    "\n",
    "        depth_first_traversal(tree, depth=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost:\n",
    "    \"\"\" \n",
    "    XGBoost for binary classification.\n",
    "    Attributes:\n",
    "        num_trees (int): Number of boosting rounds (trees).\n",
    "        max_depth (int): Maximum depth of each decision tree.\n",
    "        min_samplessplit (int): Minimum number of samples required to split an internal node.\n",
    "        learning_rate (float): Step size shrinkage used in update to prevent overfitting.\n",
    "        trees (list): List of trained decision tree models.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_trees=10, max_depth=3, min_samplessplit=2, learning_rate=0.3):\n",
    "        \"\"\" \n",
    "        Initializes the XGBoost model with the specified parameters.\n",
    "        @params:\n",
    "            num_trees (int): Number of trees to fit. Default is 10.\n",
    "            max_depth (int): Maximum depth of each tree. Default is 3.\n",
    "            min_samplessplit (int): Minimum samples required to split a node. Default is 2.\n",
    "            learning_rate (float): Learning rate for the model. Default is 0.3.\n",
    "        \"\"\"\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samplessplit = min_samplessplit\n",
    "        self.learning_rate = learning_rate\n",
    "        self.trees = []\n",
    "\n",
    "    def train(self, X, y, detailed=False):\n",
    "        \"\"\" \n",
    "        Trains the XGBoost model using the training data.\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with the training data.\n",
    "            y (numpy.ndarray): A 1D array of shape (n_samples,) with the target labels.\n",
    "            detailed (boolean): Whether to print the current tree when interating. Default is true.\n",
    "        \"\"\"\n",
    "        # Initialize predictions with zeros\n",
    "        y_pred = np.zeros_like(y, dtype=float)\n",
    "\n",
    "        # Train each tree iteratively\n",
    "        for i in range(self.num_trees):\n",
    "            # Compute gradients and hessians\n",
    "            grad, hess = self.gradient(y, y_pred)\n",
    "            \n",
    "            # Initialize and train a new decision tree\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samplessplit=self.min_samplessplit)\n",
    "            tree.train(X, y, grad, hess)\n",
    "            \n",
    "            # Make predictions using the trained tree\n",
    "            predictions = tree.predict(X)\n",
    "            \n",
    "            # Update predictions with the learning rate\n",
    "            y_pred += self.learning_rate * predictions\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            if detailed:\n",
    "                # Print the structure of the current tree\n",
    "                print(f\"Tree {i + 1}:\")\n",
    "                tree.print_tree()\n",
    "                # Calculate and print the cross-entropy loss using sigmoid\n",
    "                loss = self.cross_entropy_loss(y, 1 / (1 + np.exp(-y_pred)))\n",
    "                print(f\"Loss after Tree {i + 1}: {loss}\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "    def gradient(self, y, y_pred):\n",
    "        \"\"\" \n",
    "        Computes the gradients and hessians for the loss function.\n",
    "        @params:\n",
    "            y (numpy.ndarray): A 1D array of target labels.\n",
    "            y_pred (numpy.ndarray): A 1D array of current predictions.\n",
    "        @return:\n",
    "            tuple: A tuple containing:\n",
    "                - grad (numpy.ndarray): A 1D array of gradients for each sample.\n",
    "                - hess (numpy.ndarray): A 1D array of hessians for each sample.\n",
    "        \"\"\"\n",
    "        # Compute the first derivative (gradient)\n",
    "        grad = y_pred - y\n",
    "        \n",
    "        # For the squared error loss, the second derivative (hessian) is constant and equal to 1\n",
    "        hess = np.ones_like(y)\n",
    "        return grad, hess\n",
    "\n",
    "    def cross_entropy_loss(self, y, y_pred):\n",
    "        \"\"\" \n",
    "        Computes the cross-entropy loss between true and predicted labels.\n",
    "        @params:\n",
    "            y (numpy.ndarray): A 1D array of target labels.\n",
    "            y_pred (numpy.ndarray): A 1D array of predicted probabilities.\n",
    "        @return:\n",
    "            float: The mean cross-entropy loss.\n",
    "        \"\"\"\n",
    "        # Clip predicted probabilities to avoid log(0)\n",
    "        y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
    "        loss = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" \n",
    "        Outputs predicted labels for the input data using the trained trees.\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with the input data.\n",
    "        @return:\n",
    "            numpy.ndarray: A 1D array of predicted values for each sample.\n",
    "        \"\"\"\n",
    "        # Initialize predictions with zeros\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "\n",
    "        # Aggregate predictions from each tree\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unit tests and edge cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal dataset test passed with predictions 1.00 \n",
      "Predictions with zero gradient/hessian: [0. 0.]\n",
      "Zero gradient and Hessian test passed.\n",
      "Predictions with identical features: [0.33333333 0.33333333 0.33333333]\n",
      "Identical features test passed.\n",
      "Gain computation test passed.\n",
      "Split test passed.\n",
      "DecisionTree accuracy on linear dataset: 1.00\n",
      "DecisionTree accuracy on non-linear dataset: 0.90\n",
      "Gradients computation test passed.\n",
      "Cross entropy loss test passed.\n",
      "XGBoost accuracy on linear dataset: 1.00\n",
      "XGBoost accuracy on non-linear dataset: 0.95\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "\n",
    "# Sets random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Synthetic dataset 1: Linearly separable data\n",
    "X_linear = np.array([\n",
    "    [float(i), float(2 * i + 1)] for i in range(10)\n",
    "])\n",
    "y_linear = np.array([0 if x[0] < 5 else 1 for x in X_linear])\n",
    "y_pred_linear = np.zeros_like(y_linear, dtype=float)\n",
    "\n",
    "# Synthetic dataset 2: Non-linearly separable data\n",
    "X_nonlinear = np.random.rand(20, 2) * 10  # Random points in a 10x10 grid\n",
    "y_nonlinear = np.array([1 if x[0]**2 + x[1]**2 < 50 else 0 for x in X_nonlinear])\n",
    "y_pred_nonlinear = np.zeros_like(y_nonlinear, dtype=float)\n",
    "\n",
    "test_gain_cases = [\n",
    "    # Format: (G_L, H_L, G_R, H_R, expected_gain)\n",
    "    (10.0, 5.0, 20.0, 10.0, -2.000000165480742e-10),\n",
    "    (5.0, 2.0, 15.0, 8.0, 0.3124999997117186),\n",
    "    (0.0, 1.0, 0.0, 1.0, 0.0),\n",
    "    (10.0, 0.1, 10.0, 0.1, -4.999999418942025e-07)\n",
    "]\n",
    "\n",
    "# Additional edge cases\n",
    "# Minimal dataset\n",
    "X_minimal = np.array([[1.0, 2.0]])\n",
    "y_minimal = np.array([1])\n",
    "\n",
    "# Zero gradient and Hessian\n",
    "X_zero_grad = np.array([[1.0, 1.0], [2.0, 2.0]])\n",
    "y_zero_grad = np.array([0, 1])\n",
    "\n",
    "# Identical features\n",
    "X_identical = np.array([[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]])\n",
    "y_identical = np.array([0, 0, 1])\n",
    "\n",
    "# Creates a simple parameter dictionary\n",
    "params = {\n",
    "    'num_trees': 4,\n",
    "    'max_depth': 3,\n",
    "    'min_samplessplit': 2,\n",
    "    'learning_rate': 0.3\n",
    "}\n",
    "\n",
    "\n",
    "# Test model with a minimal dataset (1 sample).\n",
    "def test_minimal_dataset():\n",
    "    \"\"\"\n",
    "    Validates the DecisionTree model's behavior with the smallest possible dataset (one sample).\n",
    "    Purpose: Ensure the model can train and predict with minimal input data.\n",
    "    \"\"\"\n",
    "    tree = DecisionTree(max_depth=1, min_samplessplit=1)\n",
    "    tree.train(X_minimal, y_minimal, grad=np.zeros_like(y_minimal)-y_minimal, hess=np.ones_like(y_minimal))\n",
    "    predictions = tree.predict(X_minimal)\n",
    "    assert predictions.shape == y_minimal.shape\n",
    "    assert predictions[0] == pytest.approx(1, .001)\n",
    "    print(f\"Minimal dataset test passed with predictions {predictions[0]:.2f} \")\n",
    "\n",
    "\n",
    "# Test model with zero gradient and Hessian values.\n",
    "def test_zero_gradient_hessian():\n",
    "    \"\"\"\n",
    "    Checks the DecisionTree's response to a dataset with zero gradients and Hessians.\n",
    "    Purpose: Verify that the model handles edge cases where no learning signal exists.\n",
    "    \"\"\"\n",
    "    tree = DecisionTree(max_depth=2, min_samplessplit=1)\n",
    "    grad = np.zeros_like(y_zero_grad)\n",
    "    hess = np.zeros_like(y_zero_grad)\n",
    "    tree.train(X_zero_grad, y_zero_grad, grad=grad, hess=hess)\n",
    "    predictions = tree.predict(X_zero_grad)\n",
    "    print(f\"Predictions with zero gradient/hessian: {predictions}\")\n",
    "    assert predictions.shape == y_zero_grad.shape\n",
    "    print(\"Zero gradient and Hessian test passed.\")\n",
    "\n",
    "\n",
    "# Test model on dataset with identical feature values.\n",
    "def test_identical_features():\n",
    "    \"\"\"\n",
    "    Tests the DecisionTree on a dataset where all feature values are identical.\n",
    "    Purpose: Evaluate the model's ability to handle cases where no meaningful split is possible.\n",
    "    \"\"\"\n",
    "    tree = DecisionTree(max_depth=2, min_samplessplit=1)\n",
    "    tree.train(X_identical, y_identical, grad=np.zeros_like(y_identical)-y_identical, hess=np.ones_like(y_identical))\n",
    "    predictions = tree.predict(X_identical)\n",
    "    print(f\"Predictions with identical features: {predictions}\")\n",
    "    assert np.all(predictions == predictions[0]), \"Model failed on identical features dataset.\"\n",
    "    print(\"Identical features test passed.\")\n",
    "\n",
    "\n",
    "# Test gain calculation for various cases.\n",
    "def test_gain():\n",
    "    \"\"\"\n",
    "    Evaluates the correctness of the gain function used in the tree-splitting logic.\n",
    "    Purpose: Ensure gain calculations match expected values for test cases.\n",
    "    \"\"\"\n",
    "    tree = DecisionTree(max_depth=2, min_samplessplit=1)\n",
    "    # Test each case\n",
    "    for i, (G_L, H_L, G_R, H_R, expected_gain) in enumerate(test_gain_cases):\n",
    "        gain = tree.gain(G_L, H_L, G_R, H_R)\n",
    "        assert abs(gain - expected_gain) < 1e-5, f\"Test case {i+1} failed: expected {expected_gain}, got {gain}\"\n",
    "    print(\"Gain computation test passed.\")\n",
    "\n",
    "\n",
    "# Test the best split function in the DecisionTree class.\n",
    "def test_split():\n",
    "    \"\"\"\n",
    "    Assesses the DecisionTree's ability to identify the optimal split point for a dataset.\n",
    "    Purpose: Verify that the split logic works correctly for both linear and non-linear datasets.\n",
    "    \"\"\"\n",
    "    tree = DecisionTree(max_depth=2, min_samplessplit=1)\n",
    "    split_feature1, split_value1 = tree.split(X_linear, y_linear, grad=y_pred_linear-y_linear, hess=np.ones_like(y_linear))\n",
    "    split_feature2, split_value2 = tree.split(X_nonlinear, y_nonlinear, grad=np.ones_like(y_nonlinear), hess=np.ones_like(y_nonlinear))\n",
    "    assert split_feature1 == 0\n",
    "    assert split_feature2 == 0\n",
    "    assert split_value1 == pytest.approx(4.5, .001)\n",
    "    assert split_value2 == pytest.approx(0.195, .001)\n",
    "    print(\"Split test passed.\")\n",
    "\n",
    "\n",
    "# Test DecisionTree on linearly separable data.\n",
    "def test_decision_tree_with_linear_data():\n",
    "    \"\"\"\n",
    "    Validates the DecisionTree's performance on a linearly separable dataset.\n",
    "    Purpose: Ensure the model achieves 100% accuracy on simple linearly separable data.\n",
    "    \"\"\"\n",
    "    tree = DecisionTree(max_depth=3, min_samplessplit=2)\n",
    "    tree.train(X_linear, y_linear, grad=y_pred_linear-y_linear, hess=np.ones_like(y_linear))\n",
    "    predictions = tree.predict(X_linear)\n",
    "    assert predictions.shape == y_linear.shape\n",
    "    accuracy = np.mean((predictions > 0.5) == y_linear)\n",
    "    assert accuracy == 1.0, f\"Expected accuracy 1.0, got {accuracy}\"\n",
    "    print(f\"DecisionTree accuracy on linear dataset: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Test DecisionTree on non-linearly separable data.\n",
    "def test_decision_tree_with_nonlinear_data():\n",
    "    \"\"\"\n",
    "    Tests the DecisionTree's performance on a non-linearly separable dataset.\n",
    "    Purpose: Check how well the model handles more complex decision boundaries.\n",
    "    \"\"\"\n",
    "    tree = DecisionTree(max_depth=3, min_samplessplit=2)\n",
    "    tree.train(X_nonlinear, y_nonlinear, grad=y_pred_nonlinear-y_nonlinear, hess=np.ones_like(y_nonlinear))\n",
    "    predictions = tree.predict(X_nonlinear)\n",
    "    assert predictions.shape == y_nonlinear.shape\n",
    "    accuracy = np.mean((predictions > 0.5) == y_nonlinear)\n",
    "    print(f\"DecisionTree accuracy on non-linear dataset: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Test gradient and hessian computation in the XGBoost model.\n",
    "def test_compute_gradients():\n",
    "    \"\"\"\n",
    "    Validates gradient and Hessian computation in the XGBoost model for synthetic datasets.\n",
    "    Purpose: Ensure that gradient calculations are consistent with expectations.\n",
    "    \"\"\"\n",
    "    model = XGBoost(**params)\n",
    "    gradients1, _ = model.gradient(y_linear, y_pred_linear)\n",
    "    gradients2, _ = model.gradient(y_nonlinear, y_pred_nonlinear)\n",
    "    assert gradients1 == pytest.approx(np.array([0., 0., 0., 0., 0., -1., -1., -1., -1., -1.]), .001)\n",
    "    assert gradients2 == pytest.approx(np.array([0., 0., 0., 0., 0., 0., 0., -1., 0., 0., 0., 0., -1., 0., -1., 0., 0., -1., 0., 0.]), .001)\n",
    "    print(\"Gradients computation test passed.\")\n",
    "\n",
    "\n",
    "# Test cross-entropy loss calculation in the XGBoost model.\n",
    "def test_cross_entropy_loss():\n",
    "    \"\"\"\n",
    "    Verifies the accuracy of cross-entropy loss calculation in XGBoost.\n",
    "    Purpose: Ensure loss is computed correctly for different datasets.\n",
    "    \"\"\"\n",
    "    model = XGBoost(**params)\n",
    "    loss1 = model.cross_entropy_loss(y_linear, y_pred_linear)\n",
    "    loss2 = model.cross_entropy_loss(y_nonlinear, y_pred_nonlinear)\n",
    "    assert loss1 == pytest.approx(11.513, .001)\n",
    "    assert loss2 == pytest.approx(4.605, .001)\n",
    "    print(\"Cross entropy loss test passed.\")\n",
    "\n",
    "\n",
    "# Test XGBoost on linearly separable data.\n",
    "def test_xgboost_with_linear_data():\n",
    "    \"\"\"\n",
    "    Tests the XGBoost model's ability to learn from a linearly separable dataset.\n",
    "    Purpose: Validate that XGBoost achieves 100% accuracy on simple datasets.\n",
    "    \"\"\"\n",
    "    model = XGBoost(**params)\n",
    "    model.train(X_linear, y_linear, detailed=False)\n",
    "    predictions = model.predict(X_linear)\n",
    "    assert predictions.shape == y_linear.shape\n",
    "    accuracy = np.mean((predictions > 0.5) == y_linear)\n",
    "    assert accuracy == 1.0, f\"Expected accuracy 1.0, got {accuracy}\"\n",
    "    print(f\"XGBoost accuracy on linear dataset: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Test XGBoost on non-linearly separable data.\n",
    "def test_xgboost_with_nonlinear_data():\n",
    "    \"\"\"\n",
    "    Evaluates the performance of the XGBoost model on non-linearly separable data.\n",
    "    Purpose: Measure the model's capability to adapt to complex decision boundaries.\n",
    "    \"\"\"\n",
    "    model = XGBoost(**params)\n",
    "    model.train(X_nonlinear, y_nonlinear, detailed=False)\n",
    "    predictions = model.predict(X_nonlinear)\n",
    "    assert predictions.shape == y_nonlinear.shape\n",
    "    accuracy = np.mean((predictions > 0.5) == y_nonlinear)\n",
    "    print(f\"XGBoost accuracy on non-linear dataset: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Run tests with synthetic datasets\n",
    "test_minimal_dataset()\n",
    "test_zero_gradient_hessian()\n",
    "test_identical_features()\n",
    "test_gain()\n",
    "test_split()\n",
    "test_decision_tree_with_linear_data()\n",
    "test_decision_tree_with_nonlinear_data()\n",
    "test_compute_gradients()\n",
    "test_cross_entropy_loss()\n",
    "test_xgboost_with_linear_data()\n",
    "test_xgboost_with_nonlinear_data()\n",
    "\n",
    "print(\"All tests passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons of Previous Works Using XGBoost\n",
    "\n",
    "### Introduction of Python XBGoost Module:\n",
    "\n",
    "The XGBoost Python module is the implementation of the XGBoost algorithm in Python. This module supports loading datasets and training models using the sklearn estimator interface from the sklearn module. With this interface, users can set the loss function based on the task and choose the type of tree used in XGBoost. This allows XGBoost to make predictions on different datasets. The previous works we selected all used this module for training and prediction on different datasets (Pedregosa et al., 2011)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Breast Cancer Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work uses XGBoost to diagnose whether a breast mass is benign or malignant. The dataset used is the Breast Cancer Wisconsin (Diagnostic) Data Set. The features of this dataset are derived from a digitized image of a fine needle aspirate (FNA) of a breast mass. Below is a list of features:\n",
    "\n",
    "| **Feature**             | **Description**                                                        |\n",
    "|--------------------------|------------------------------------------------------------------------|\n",
    "| **ID number**            | Identifier for each case                                              |\n",
    "| **Diagnosis**            | M = malignant, B = benign                                             |\n",
    "| **radius**               | Mean of distances from center to points on the perimeter              |\n",
    "| **texture**              | Standard deviation of gray-scale values                               |\n",
    "| **perimeter**            | Perimeter of the contour                                              |\n",
    "| **area**                 | Area within the contour                                               |\n",
    "| **smoothness**           | Local variation in radius lengths                                     |\n",
    "| **compactness**          | Perimeter² / Area - 1.0                                               |\n",
    "| **concavity**            | Severity of concave portions of the contour                           |\n",
    "| **concave points**       | Number of concave portions of the contour                             |\n",
    "| **symmetry**             | Symmetry of the contour                                               |\n",
    "| **fractal dimension**    | \"Coastline approximation\" - 1                                         |\n",
    "\n",
    "To facilitate result comparison, we made the following improvements:\n",
    "\n",
    "- Remove the ID number column as the irrelevant column.\n",
    "- Encode the values in the Diagnosis column, where M = malignant and B = benign, into Malignant = 1 and Benign = 0.\n",
    "- Set the number of decision trees used by XGBoost to 5, the maximum depth of the trees to 5, and the learning rate to 0.3.\n",
    "\n",
    "We split the dataset into 20% training and 80% testing sets, using 5-fold cross-validation to evaluate the accuracy of our model and the previous work's model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing with OUR XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 1:\n",
      "0:[f7<0.060896] yes=1,no=2,missing=2\n",
      "\t1:[f20<0.116134] yes=3,no=4,missing=4\n",
      "\t\t3:[f10<0.795390] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f24<1.870977] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:[f14<-1.244043] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=0.142857\n",
      "\t\t\t\t\t28:leaf=0.003984\n",
      "\t\t\t\t16:leaf=0.500000\n",
      "\t\t\t8:leaf=0.666667\n",
      "\t\t4:[f1<-0.721309] yes=9,no=10,missing=10\n",
      "\t\t\t9:[f0<0.274843] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=-0.000000\n",
      "\t\t\t\t18:[f0<0.594359] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=-0.000000\n",
      "\t\t\t\t\t30:leaf=-0.000000\n",
      "\t\t\t10:[f17<-0.270993] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:[f0<-0.146918] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=1.000000\n",
      "\t\t\t\t\t32:leaf=1.000000\n",
      "\t\t\t\t20:leaf=-0.000000\n",
      "\t2:[f27<0.486395] yes=5,no=6,missing=6\n",
      "\t\t5:[f22<0.237953] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f1<0.410809] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:[f0<-1.137276] yes=33,no=34,missing=34\n",
      "\t\t\t\t\t33:leaf=-0.000000\n",
      "\t\t\t\t\t34:leaf=-0.000000\n",
      "\t\t\t\t22:[f0<0.087394] yes=35,no=36,missing=36\n",
      "\t\t\t\t\t35:leaf=1.000000\n",
      "\t\t\t\t\t36:leaf=1.000000\n",
      "\t\t\t12:[f0<0.632701] yes=23,no=24,missing=24\n",
      "\t\t\t\t23:leaf=1.000000\n",
      "\t\t\t\t24:[f0<0.876953] yes=37,no=38,missing=38\n",
      "\t\t\t\t\t37:leaf=1.000000\n",
      "\t\t\t\t\t38:leaf=1.000000\n",
      "\t\t6:[f16<3.440249] yes=13,no=14,missing=14\n",
      "\t\t\t13:[f0<-0.714947] yes=25,no=26,missing=26\n",
      "\t\t\t\t25:leaf=1.000000\n",
      "\t\t\t\t26:[f0<-0.562999] yes=39,no=40,missing=40\n",
      "\t\t\t\t\t39:leaf=1.000000\n",
      "\t\t\t\t\t40:leaf=1.000000\n",
      "\t\t\t14:leaf=-0.000000\n",
      "Loss after Tree 1: 0.6435127119020765\n",
      "\n",
      "\n",
      "Tree 2:\n",
      "0:[f27<0.422443] yes=1,no=2,missing=2\n",
      "\t1:[f23<0.135125] yes=3,no=4,missing=4\n",
      "\t\t3:[f1<0.736599] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f10<0.687294] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:[f19<-0.938027] yes=25,no=26,missing=26\n",
      "\t\t\t\t\t25:leaf=0.105287\n",
      "\t\t\t\t\t26:leaf=-0.002150\n",
      "\t\t\t\t16:leaf=0.200000\n",
      "\t\t\t8:[f20<0.084036] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:[f1<0.773832] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=0.849402\n",
      "\t\t\t\t\t28:leaf=0.047147\n",
      "\t\t\t\t18:[f0<0.068933] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=0.700000\n",
      "\t\t\t\t\t30:leaf=0.700000\n",
      "\t\t4:[f26<-0.390943] yes=9,no=10,missing=10\n",
      "\t\t\t9:[f0<0.842871] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.000000\n",
      "\t\t\t\t20:leaf=0.350000\n",
      "\t\t\t10:[f15<0.166655] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:[f0<0.304664] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=0.700000\n",
      "\t\t\t\t\t32:leaf=0.700000\n",
      "\t\t\t\t22:[f0<1.028901] yes=33,no=34,missing=34\n",
      "\t\t\t\t\t33:leaf=0.700000\n",
      "\t\t\t\t\t34:leaf=0.700000\n",
      "\t2:[f2<-0.830149] yes=5,no=6,missing=6\n",
      "\t\t5:[f5<0.876677] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.001195\n",
      "\t\t\t12:leaf=-0.000000\n",
      "\t\t6:[f11<-1.376912] yes=13,no=14,missing=14\n",
      "\t\t\t13:leaf=-0.000598\n",
      "\t\t\t14:[f6<-0.030751] yes=23,no=24,missing=24\n",
      "\t\t\t\t23:[f27<0.553392] yes=35,no=36,missing=36\n",
      "\t\t\t\t\t35:leaf=-0.000598\n",
      "\t\t\t\t\t36:leaf=0.700000\n",
      "\t\t\t\t24:[f16<2.994288] yes=37,no=38,missing=38\n",
      "\t\t\t\t\t37:leaf=0.701095\n",
      "\t\t\t\t\t38:leaf=0.350000\n",
      "Loss after Tree 2: 0.613821695762677\n",
      "\n",
      "\n",
      "Tree 3:\n",
      "0:[f7<0.060896] yes=1,no=2,missing=2\n",
      "\t1:[f20<0.116134] yes=3,no=4,missing=4\n",
      "\t\t3:[f10<0.795390] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f21<2.181745] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:[f14<-1.244043] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=0.096041\n",
      "\t\t\t\t\t28:leaf=-0.000624\n",
      "\t\t\t\t16:leaf=0.202998\n",
      "\t\t\t8:leaf=0.421952\n",
      "\t\t4:[f1<-0.721309] yes=9,no=10,missing=10\n",
      "\t\t\t9:[f0<0.594359] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:[f0<0.274843] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=0.000645\n",
      "\t\t\t\t\t30:leaf=0.000645\n",
      "\t\t\t\t18:leaf=-0.052177\n",
      "\t\t\t10:[f17<-0.270993] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:[f11<0.157207] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=0.490000\n",
      "\t\t\t\t\t32:leaf=0.542500\n",
      "\t\t\t\t20:leaf=-0.000000\n",
      "\t2:[f22<0.214124] yes=5,no=6,missing=6\n",
      "\t\t5:[f21<-0.003619] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f27<0.776462] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:[f24<-1.361262] yes=33,no=34,missing=34\n",
      "\t\t\t\t\t33:leaf=-0.082500\n",
      "\t\t\t\t\t34:leaf=0.000542\n",
      "\t\t\t\t22:leaf=0.489672\n",
      "\t\t\t12:[f12<-0.647777] yes=23,no=24,missing=24\n",
      "\t\t\t\t23:leaf=0.245090\n",
      "\t\t\t\t24:[f5<-0.046260] yes=35,no=36,missing=36\n",
      "\t\t\t\t\t35:leaf=0.587928\n",
      "\t\t\t\t\t36:leaf=0.487330\n",
      "\t\t6:[f14<3.783160] yes=13,no=14,missing=14\n",
      "\t\t\t13:[f27<0.419398] yes=25,no=26,missing=26\n",
      "\t\t\t\t25:[f0<0.760507] yes=37,no=38,missing=38\n",
      "\t\t\t\t\t37:leaf=0.490000\n",
      "\t\t\t\t\t38:leaf=0.490000\n",
      "\t\t\t\t26:[f6<-0.056552] yes=39,no=40,missing=40\n",
      "\t\t\t\t\t39:leaf=0.490000\n",
      "\t\t\t\t\t40:leaf=0.489672\n",
      "\t\t\t14:leaf=0.542500\n",
      "Loss after Tree 3: 0.5949167203973654\n",
      "\n",
      "\n",
      "Tree 4:\n",
      "0:[f27<0.422443] yes=1,no=2,missing=2\n",
      "\t1:[f23<0.135125] yes=3,no=4,missing=4\n",
      "\t\t3:[f1<0.531817] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f13<0.246703] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:[f13<0.183999] yes=25,no=26,missing=26\n",
      "\t\t\t\t\t25:leaf=-0.003007\n",
      "\t\t\t\t\t26:leaf=0.306948\n",
      "\t\t\t\t16:leaf=-0.210918\n",
      "\t\t\t8:[f18<-0.778813] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:[f17<-0.797364] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=0.163924\n",
      "\t\t\t\t\t28:leaf=0.778007\n",
      "\t\t\t\t18:[f7<0.002343] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=0.018677\n",
      "\t\t\t\t\t30:leaf=0.374026\n",
      "\t\t4:[f26<-0.390943] yes=9,no=10,missing=10\n",
      "\t\t\t9:[f1<-0.096491] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.044673\n",
      "\t\t\t\t20:leaf=0.216125\n",
      "\t\t\t10:[f8<-0.960631] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:leaf=0.335125\n",
      "\t\t\t\t22:[f14<-0.682021] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=0.343000\n",
      "\t\t\t\t\t32:leaf=0.343000\n",
      "\t2:[f16<3.440249] yes=5,no=6,missing=6\n",
      "\t\t5:[f11<-1.376912] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.000406\n",
      "\t\t\t12:[f20<-0.292854] yes=23,no=24,missing=24\n",
      "\t\t\t\t23:[f4<0.792763] yes=33,no=34,missing=34\n",
      "\t\t\t\t\t33:leaf=-0.036998\n",
      "\t\t\t\t\t34:leaf=0.343473\n",
      "\t\t\t\t24:[f26<-0.211516] yes=35,no=36,missing=36\n",
      "\t\t\t\t\t35:leaf=0.170971\n",
      "\t\t\t\t\t36:leaf=0.345744\n",
      "\t\t6:[f8<1.233586] yes=13,no=14,missing=14\n",
      "\t\t\t13:leaf=-0.040450\n",
      "\t\t\t14:leaf=-0.000163\n",
      "Loss after Tree 4: 0.5822573940429663\n",
      "\n",
      "\n",
      "Tree 5:\n",
      "0:[f27<0.422443] yes=1,no=2,missing=2\n",
      "\t1:[f20<0.110957] yes=3,no=4,missing=4\n",
      "\t\t3:[f10<0.795390] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f26<-0.306986] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:[f14<-1.246544] yes=25,no=26,missing=26\n",
      "\t\t\t\t\t25:leaf=-0.070122\n",
      "\t\t\t\t\t26:leaf=-0.004830\n",
      "\t\t\t\t16:[f15<-0.731490] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=0.700955\n",
      "\t\t\t\t\t28:leaf=0.005834\n",
      "\t\t\t8:[f5<-0.791527] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=0.473599\n",
      "\t\t\t\t18:leaf=-0.147642\n",
      "\t\t4:[f1<-0.678258] yes=9,no=10,missing=10\n",
      "\t\t\t9:[f1<-1.328674] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.037296\n",
      "\t\t\t\t20:[f0<0.575898] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=0.001361\n",
      "\t\t\t\t\t30:leaf=0.009292\n",
      "\t\t\t10:[f11<0.780434] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:[f14<0.001007] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=0.260225\n",
      "\t\t\t\t\t32:leaf=0.151639\n",
      "\t\t\t\t22:leaf=0.080938\n",
      "\t2:[f16<3.440249] yes=5,no=6,missing=6\n",
      "\t\t5:[f11<-1.376912] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.000284\n",
      "\t\t\t12:[f20<-0.292854] yes=23,no=24,missing=24\n",
      "\t\t\t\t23:[f4<0.792763] yes=33,no=34,missing=34\n",
      "\t\t\t\t\t33:leaf=-0.025899\n",
      "\t\t\t\t\t34:leaf=0.240431\n",
      "\t\t\t\t24:[f6<-0.277770] yes=35,no=36,missing=36\n",
      "\t\t\t\t\t35:leaf=0.093578\n",
      "\t\t\t\t\t36:leaf=0.242399\n",
      "\t\t6:[f0<-1.129465] yes=13,no=14,missing=14\n",
      "\t\t\t13:leaf=0.005686\n",
      "\t\t\t14:leaf=-0.034114\n",
      "Loss after Tree 5: 0.573200214537392\n",
      "\n",
      "\n",
      "Model Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset from a CSV file using numpy's genfromtxt\n",
    "data = np.genfromtxt('../data/breast+cancer+wisconsin+diagnostic/wdbc.data', delimiter=',', dtype=str)\n",
    "\n",
    "# Extract features and convert them to float\n",
    "X = data[:, 2:].astype(float)  # Features start from the 3rd column (index 2)\n",
    "# Convert the labels to binary (Malignant -> 1, Benign -> 0)\n",
    "y = np.where(data[:, 1] == 'M', 1, 0)\n",
    "\n",
    "# Normalize the features using mean and standard deviation\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the XGBoost model we implemented earlier\n",
    "model = XGBoost(num_trees=5, max_depth=5, learning_rate=0.3)\n",
    "\n",
    "# Trains the XGBoost model on the training data.\n",
    "model.train(X_train, y_train, detailed='true')\n",
    "\n",
    "# Generates predictions on the test data.\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary labels (0 or 1) using a threshold of 0.5\n",
    "predictions = np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(\"Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.9561\n",
      "Fold 2 Accuracy: 0.9649\n",
      "Fold 3 Accuracy: 0.9211\n",
      "Fold 4 Accuracy: 0.9561\n",
      "Fold 5 Accuracy: 0.9204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define 5-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store accuracy for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform 5-Fold Cross-Validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Initialize and train the XGBoost model on the training data\n",
    "    model = XGBoost(num_trees=5, max_depth=5, learning_rate=0.3)\n",
    "    model.train(X_train, y_train, detailed=False)\n",
    "    \n",
    "    # Generate predictions on the test data\n",
    "    y_prob = model.predict(X_test)\n",
    "    \n",
    "    # Convert predictions to binary labels (0 or 1) using a threshold of 0.5\n",
    "    predictions = np.where(y_prob >= 0.5, 1, 0)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = np.mean(predictions == y_test)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(f'Fold {fold} Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the accuracy scores for each fold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), accuracy_scores, marker='o', linestyle='-', color='b', label='Fold Accuracy')\n",
    "plt.axhline(mean_accuracy, color='r', linestyle='--', label=f'Average Accuracy: {mean_accuracy:.4f}')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('5-Fold Cross-Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing with imported XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.3, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 5, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 5, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "Number of estimators: 5\n",
      "Max depth: 5\n",
      "Learning rate: 0.3\n",
      "Tree 1 structure:\n",
      "0:[f27<0.42320466] yes=1,no=2,missing=2\n",
      "\t1:[f23<0.151913315] yes=3,no=4,missing=4\n",
      "\t\t3:[f13<0.0616690516] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f1<0.740089118] yes=11,no=12,missing=12\n",
      "\t\t\t\t11:leaf=-0.466026366\n",
      "\t\t\t\t12:[f22<-0.20734556] yes=13,no=14,missing=14\n",
      "\t\t\t\t\t13:leaf=-0.357332468\n",
      "\t\t\t\t\t14:leaf=0.156942263\n",
      "\t\t\t8:leaf=0.0610413142\n",
      "\t\t4:[f26<-0.377509862] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=0.0178343765\n",
      "\t\t\t10:leaf=0.624066651\n",
      "\t2:[f20<-0.293889403] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=-0.035497915\n",
      "\t\t6:leaf=0.752050877\n",
      "\n",
      "\n",
      "Tree 2 structure:\n",
      "0:[f7<0.046967078] yes=1,no=2,missing=2\n",
      "\t1:[f20<0.118204817] yes=3,no=4,missing=4\n",
      "\t\t3:[f12<0.613808632] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f14<-1.23437631] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=-0.114261463\n",
      "\t\t\t\t14:[f24<1.49618065] yes=17,no=18,missing=18\n",
      "\t\t\t\t\t17:leaf=-0.403840512\n",
      "\t\t\t\t\t18:leaf=-0.0984430537\n",
      "\t\t\t8:leaf=0.0410378166\n",
      "\t\t4:[f1<-0.230297849] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.182360739\n",
      "\t\t\t10:leaf=0.395994633\n",
      "\t2:[f22<0.218591928] yes=5,no=6,missing=6\n",
      "\t\t5:[f21<-0.0321165733] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f4<1.56846631] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.365916401\n",
      "\t\t\t\t16:leaf=0.00907746423\n",
      "\t\t\t12:leaf=0.470775664\n",
      "\t\t6:leaf=0.524210393\n",
      "\n",
      "\n",
      "Tree 3 structure:\n",
      "0:[f7<0.046967078] yes=1,no=2,missing=2\n",
      "\t1:[f20<0.118204817] yes=3,no=4,missing=4\n",
      "\t\t3:[f12<0.613808632] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f21<1.25272095] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:[f19<-0.927435935] yes=23,no=24,missing=24\n",
      "\t\t\t\t\t23:leaf=-0.10368415\n",
      "\t\t\t\t\t24:leaf=-0.370571643\n",
      "\t\t\t\t16:[f1<1.82915652] yes=25,no=26,missing=26\n",
      "\t\t\t\t\t25:leaf=0.0561646484\n",
      "\t\t\t\t\t26:leaf=-0.241992071\n",
      "\t\t\t8:leaf=0.0343015306\n",
      "\t\t4:[f1<-0.82835412] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.215078056\n",
      "\t\t\t10:[f20<0.372916341] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=0.361676097\n",
      "\t\t\t\t18:leaf=0.0599818453\n",
      "\t2:[f22<-0.150752455] yes=5,no=6,missing=6\n",
      "\t\t5:[f21<-0.0321165733] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.270020843\n",
      "\t\t\t12:leaf=0.190431967\n",
      "\t\t6:[f21<-1.04011965] yes=13,no=14,missing=14\n",
      "\t\t\t13:[f7<0.954141438] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.247036889\n",
      "\t\t\t\t20:leaf=0.248852536\n",
      "\t\t\t14:[f16<2.24493885] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:leaf=0.433617115\n",
      "\t\t\t\t22:leaf=0.118983932\n",
      "\n",
      "\n",
      "Tree 4 structure:\n",
      "0:[f7<0.046967078] yes=1,no=2,missing=2\n",
      "\t1:[f20<0.118204817] yes=3,no=4,missing=4\n",
      "\t\t3:[f13<0.0533084013] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f14<-1.23437631] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.05130082\n",
      "\t\t\t\t16:[f21<1.22666597] yes=21,no=22,missing=22\n",
      "\t\t\t\t\t21:leaf=-0.344956666\n",
      "\t\t\t\t\t22:leaf=-0.122661427\n",
      "\t\t\t8:leaf=0.0472804122\n",
      "\t\t4:[f1<0.0582584739] yes=9,no=10,missing=10\n",
      "\t\t\t9:[f0<0.4353109] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=0.0581673197\n",
      "\t\t\t\t18:leaf=-0.229364052\n",
      "\t\t\t10:leaf=0.320933908\n",
      "\t2:[f27<0.487156361] yes=5,no=6,missing=6\n",
      "\t\t5:[f21<-0.455510437] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.270272046\n",
      "\t\t\t12:[f0<-0.166799188] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.11168804\n",
      "\t\t\t\t20:leaf=0.32427609\n",
      "\t\t6:[f19<2.10803103] yes=13,no=14,missing=14\n",
      "\t\t\t13:leaf=0.381736666\n",
      "\t\t\t14:leaf=0.0144605841\n",
      "\n",
      "\n",
      "Tree 5 structure:\n",
      "0:[f22<-0.165645376] yes=1,no=2,missing=2\n",
      "\t1:[f7<0.200441271] yes=3,no=4,missing=4\n",
      "\t\t3:[f13<-0.00543616246] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.320362598\n",
      "\t\t\t8:leaf=0.0600373857\n",
      "\t\t4:leaf=0.0861860961\n",
      "\t2:[f26<-0.305546999] yes=5,no=6,missing=6\n",
      "\t\t5:[f1<0.00473592943] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.25152719\n",
      "\t\t\t10:leaf=0.0500616021\n",
      "\t\t6:[f21<-0.986381173] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f7<0.396991432] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=-0.231403232\n",
      "\t\t\t\t14:leaf=0.153383717\n",
      "\t\t\t12:[f24<-1.2961657] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.0426249802\n",
      "\t\t\t\t16:leaf=0.347636878\n",
      "\n",
      "\n",
      "Model Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data from a CSV file\n",
    "data = np.genfromtxt('../data/breast+cancer+wisconsin+diagnostic/wdbc.data', delimiter=',', dtype=str)\n",
    "\n",
    "# Extract features and convert them to float for numerical operations\n",
    "X = data[:, 2:].astype(float)  # Features start from the 3rd column (index 2)\n",
    "\n",
    "# Convert labels from 'M' (Malignant) and 'B' (Benign) to binary (1 and 0)\n",
    "y = np.where(data[:, 1] == 'M', 1, 0)\n",
    "\n",
    "# Normalize the features by subtracting the mean and dividing by the standard deviation\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBoost model with log loss as the evaluation metric\n",
    "model = xgb.XGBClassifier(n_estimators=5, max_depth=5, learning_rate=0.3, eval_metric='logloss')\n",
    "\n",
    "# Fits the XGBoost model to the training data.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve and print model parameters for reference\n",
    "params = model.get_params()\n",
    "print(params)\n",
    "n_estimators = params['n_estimators']\n",
    "max_depth = params['max_depth']\n",
    "learning_rate = params['learning_rate']\n",
    "\n",
    "print(\"Number of estimators:\", n_estimators)\n",
    "print(\"Max depth:\", max_depth)\n",
    "print(\"Learning rate:\", learning_rate)\n",
    "\n",
    "# Retrieve the trained booster (underlying model) from XGBoost\n",
    "booster = model.get_booster()\n",
    "\n",
    "# Iterate over each tree in the model and print its structure\n",
    "for i, tree in enumerate(booster.get_dump()):\n",
    "    print(f\"Tree {i + 1} structure:\\n{tree}\\n\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_s = model.predict(X_test)\n",
    "\n",
    "# Compute and print the accuracy score\n",
    "accuracy_s = accuracy_score(y_test, y_pred_s)\n",
    "print(\"Model Accuracy:\", accuracy_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.9561\n",
      "Fold 2 Accuracy: 0.9474\n",
      "Fold 3 Accuracy: 0.9298\n",
      "Fold 4 Accuracy: 0.9211\n",
      "Fold 5 Accuracy: 0.9381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define 5-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store accuracy for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform 5-Fold Cross-Validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Create an XGBoost model with log loss as the evaluation metric\n",
    "    model = xgb.XGBClassifier(n_estimators=5, max_depth=5, eval_metric='logloss')\n",
    "    \n",
    "    # Fits the XGBoost model to the training data.\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(f'Fold {fold} Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "mean_accuracy_s = np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy scores for each fold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), accuracy_scores, marker='o', linestyle='-', color='b', label='Fold Accuracy')\n",
    "plt.axhline(mean_accuracy_s, color='r', linestyle='--', label=f'Average Accuracy: {mean_accuracy_s:.4f}')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('5-Fold Cross-Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results 1\n",
    "\n",
    "From the comparison of the two figures, it can be seen that under the 5-fold experiment, our average accuracy is 0.52% higher than the previous work. This shows that we successfully reproduced the previous work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work uses XGBoost to predict customer retention based on information such as credit score, age, and income. The dataset used is Churn_Predictions_Personal. This dataset includes the following features:\n",
    "\n",
    "| **Feature**        | **Description**                                                                 |\n",
    "|---------------------|---------------------------------------------------------------------------------|\n",
    "| **RowNumber**        | The row number in the dataset (used as an index).                               |\n",
    "| **CustomerId**       | A unique identifier for each customer.                                          |\n",
    "| **Surname**          | The last name of the customer.                                                  |\n",
    "| **CreditScore**      | The credit score of the customer.                                               |\n",
    "| **Geography**        | The location or country of the customer.                                        |\n",
    "| **Gender**           | The gender of the customer (e.g., Male, Female).                                |\n",
    "| **Age**              | The age of the customer.                                                        |\n",
    "| **Tenure**           | The number of years the customer has been with the provider.                    |\n",
    "| **Balance**          | The account balance of the customer.                                            |\n",
    "| **NumOfProducts**    | The number of products the customer has with the provider.                      |\n",
    "| **HasCrCard**        | Whether the customer has a credit card (1 = Yes, 0 = No).                       |\n",
    "| **IsActiveMember**   | Whether the customer is an active member (1 = Yes, 0 = No).                     |\n",
    "| **EstimatedSalary**  | The estimated salary of the customer.                                           |\n",
    "| **Exited**           | Whether the customer exited the bank (1 = Yes, 0 = No).                         |\n",
    "\n",
    "To facilitate result comparison, we made the following improvements:\n",
    "\n",
    "- Remove the RowNumber, CustomerId, and Surname columns as the irrelevant columns.\n",
    "- Encode the Gender and Geography features with the LabelEncoder\n",
    "- Set the number of decision trees used by XGBoost to 5, the maximum depth of the trees to 5, and the learning rate to 0.3.\n",
    "\n",
    "We split the dataset into 20% training and 80% testing sets, using 5-fold cross-validation to evaluate the accuracy of our model and the previous work's model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing with OUR XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 1:\n",
      "0:[f3<43.000000] yes=1,no=2,missing=2\n",
      "\t1:[f6<2.000000] yes=3,no=4,missing=4\n",
      "\t\t3:[f3<38.000000] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f1<0.000000] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.000000\n",
      "\t\t\t\t16:[f1<0.000000] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=-0.000000\n",
      "\t\t\t\t\t32:leaf=0.132921\n",
      "\t\t\t8:[f8<0.000000] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=-0.000000\n",
      "\t\t\t\t18:[f8<0.000000] yes=33,no=34,missing=34\n",
      "\t\t\t\t\t33:leaf=-0.000000\n",
      "\t\t\t\t\t34:leaf=0.256637\n",
      "\t\t4:[f6<2.500000] yes=9,no=10,missing=10\n",
      "\t\t\t9:[f5<0.000000] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.000000\n",
      "\t\t\t\t20:[f5<0.000000] yes=35,no=36,missing=36\n",
      "\t\t\t\t\t35:leaf=-0.000000\n",
      "\t\t\t\t\t36:leaf=0.044476\n",
      "\t\t\t10:[f5<0.000000] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:leaf=-0.000000\n",
      "\t\t\t\t22:[f5<0.000000] yes=37,no=38,missing=38\n",
      "\t\t\t\t\t37:leaf=-0.000000\n",
      "\t\t\t\t\t38:leaf=0.776000\n",
      "\t2:[f8<0.500000] yes=5,no=6,missing=6\n",
      "\t\t5:[f3<50.000000] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f6<1.500000] yes=23,no=24,missing=24\n",
      "\t\t\t\t23:[f3<45.000000] yes=39,no=40,missing=40\n",
      "\t\t\t\t\t39:leaf=0.432000\n",
      "\t\t\t\t\t40:leaf=0.632184\n",
      "\t\t\t\t24:[f6<2.000000] yes=41,no=42,missing=42\n",
      "\t\t\t\t\t41:leaf=-0.000000\n",
      "\t\t\t\t\t42:leaf=0.279070\n",
      "\t\t\t12:[f3<50.000000] yes=25,no=26,missing=26\n",
      "\t\t\t\t25:leaf=-0.000000\n",
      "\t\t\t\t26:[f3<50.000000] yes=43,no=44,missing=44\n",
      "\t\t\t\t\t43:leaf=-0.000000\n",
      "\t\t\t\t\t44:leaf=0.827848\n",
      "\t\t6:[f6<2.000000] yes=13,no=14,missing=14\n",
      "\t\t\t13:[f3<58.000000] yes=27,no=28,missing=28\n",
      "\t\t\t\t27:[f1<2.000000] yes=45,no=46,missing=46\n",
      "\t\t\t\t\t45:leaf=0.470405\n",
      "\t\t\t\t\t46:leaf=0.272000\n",
      "\t\t\t\t28:[f3<71.000000] yes=47,no=48,missing=48\n",
      "\t\t\t\t\t47:leaf=0.208333\n",
      "\t\t\t\t\t48:leaf=0.057692\n",
      "\t\t\t14:[f6<3.000000] yes=29,no=30,missing=30\n",
      "\t\t\t\t29:[f5<43031.970000] yes=49,no=50,missing=50\n",
      "\t\t\t\t\t49:leaf=0.039474\n",
      "\t\t\t\t\t50:leaf=0.221311\n",
      "\t\t\t\t30:[f1<0.000000] yes=51,no=52,missing=52\n",
      "\t\t\t\t\t51:leaf=-0.000000\n",
      "\t\t\t\t\t52:leaf=0.929825\n",
      "Loss after Tree 1: 0.6974359254905954\n",
      "\n",
      "\n",
      "Tree 2:\n",
      "0:[f3<44.000000] yes=1,no=2,missing=2\n",
      "\t1:[f6<3.000000] yes=3,no=4,missing=4\n",
      "\t\t3:[f6<1.000000] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.000000\n",
      "\t\t\t8:[f6<1.000000] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.000000\n",
      "\t\t\t\t16:[f6<1.000000] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=-0.000000\n",
      "\t\t\t\t\t28:leaf=0.076945\n",
      "\t\t4:[f5<0.000000] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.000000\n",
      "\t\t\t10:[f5<0.000000] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=-0.000000\n",
      "\t\t\t\t18:[f5<0.000000] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=-0.000000\n",
      "\t\t\t\t\t30:leaf=0.566497\n",
      "\t2:[f8<1.000000] yes=5,no=6,missing=6\n",
      "\t\t5:[f3<51.000000] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f6<2.500000] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:[f6<2.000000] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=0.419312\n",
      "\t\t\t\t\t32:leaf=0.094633\n",
      "\t\t\t\t20:[f3<49.500000] yes=33,no=34,missing=34\n",
      "\t\t\t\t\t33:leaf=0.916279\n",
      "\t\t\t\t\t34:leaf=0.751646\n",
      "\t\t\t12:[f3<73.500000] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:[f3<52.000000] yes=35,no=36,missing=36\n",
      "\t\t\t\t\t35:leaf=0.447298\n",
      "\t\t\t\t\t36:leaf=0.640534\n",
      "\t\t\t\t22:[f0<587.000000] yes=37,no=38,missing=38\n",
      "\t\t\t\t\t37:leaf=0.251646\n",
      "\t\t\t\t\t38:leaf=-0.248354\n",
      "\t\t6:[f6<3.000000] yes=13,no=14,missing=14\n",
      "\t\t\t13:[f6<1.500000] yes=23,no=24,missing=24\n",
      "\t\t\t\t23:[f3<58.000000] yes=39,no=40,missing=40\n",
      "\t\t\t\t\t39:leaf=0.314766\n",
      "\t\t\t\t\t40:leaf=0.120909\n",
      "\t\t\t\t24:[f5<89170.515000] yes=41,no=42,missing=42\n",
      "\t\t\t\t\t41:leaf=0.035050\n",
      "\t\t\t\t\t42:leaf=0.173607\n",
      "\t\t\t14:[f1<0.000000] yes=25,no=26,missing=26\n",
      "\t\t\t\t25:leaf=-0.000000\n",
      "\t\t\t\t26:[f1<0.000000] yes=43,no=44,missing=44\n",
      "\t\t\t\t\t43:leaf=-0.000000\n",
      "\t\t\t\t\t44:leaf=0.646979\n",
      "Loss after Tree 2: 0.7016555031904468\n",
      "\n",
      "\n",
      "Tree 3:\n",
      "0:[f3<40.000000] yes=1,no=2,missing=2\n",
      "\t1:[f6<3.000000] yes=3,no=4,missing=4\n",
      "\t\t3:[f6<1.000000] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.000000\n",
      "\t\t\t8:[f6<1.000000] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.000000\n",
      "\t\t\t\t16:[f6<1.000000] yes=25,no=26,missing=26\n",
      "\t\t\t\t\t25:leaf=-0.000000\n",
      "\t\t\t\t\t26:leaf=0.037580\n",
      "\t\t4:[f5<0.000000] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.000000\n",
      "\t\t\t10:[f5<0.000000] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=-0.000000\n",
      "\t\t\t\t18:[f5<0.000000] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=-0.000000\n",
      "\t\t\t\t\t28:leaf=0.363918\n",
      "\t2:[f6<2.500000] yes=5,no=6,missing=6\n",
      "\t\t5:[f6<1.000000] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.000000\n",
      "\t\t\t12:[f6<1.000000] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.000000\n",
      "\t\t\t\t20:[f6<1.000000] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=-0.000000\n",
      "\t\t\t\t\t30:leaf=0.168689\n",
      "\t\t6:[f3<66.000000] yes=13,no=14,missing=14\n",
      "\t\t\t13:[f3<40.000000] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:leaf=-0.000000\n",
      "\t\t\t\t22:[f3<40.000000] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=-0.000000\n",
      "\t\t\t\t\t32:leaf=0.530731\n",
      "\t\t\t14:[f6<3.000000] yes=23,no=24,missing=24\n",
      "\t\t\t\t23:leaf=-0.000000\n",
      "\t\t\t\t24:[f6<3.000000] yes=33,no=34,missing=34\n",
      "\t\t\t\t\t33:leaf=-0.000000\n",
      "\t\t\t\t\t34:leaf=-0.066536\n",
      "Loss after Tree 3: 0.7073593127380651\n",
      "\n",
      "\n",
      "Tree 4:\n",
      "0:[f3<45.000000] yes=1,no=2,missing=2\n",
      "\t1:[f6<1.000000] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.000000\n",
      "\t\t4:[f6<1.000000] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.000000\n",
      "\t\t\t8:[f6<1.000000] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=-0.000000\n",
      "\t\t\t\t14:[f6<1.000000] yes=21,no=22,missing=22\n",
      "\t\t\t\t\t21:leaf=-0.000000\n",
      "\t\t\t\t\t22:leaf=0.040787\n",
      "\t2:[f8<1.000000] yes=5,no=6,missing=6\n",
      "\t\t5:[f6<1.000000] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.000000\n",
      "\t\t\t10:[f6<1.000000] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.000000\n",
      "\t\t\t\t16:[f6<1.000000] yes=23,no=24,missing=24\n",
      "\t\t\t\t\t23:leaf=-0.000000\n",
      "\t\t\t\t\t24:leaf=0.277327\n",
      "\t\t6:[f3<61.000000] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f2<0.000000] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=-0.000000\n",
      "\t\t\t\t18:[f2<0.000000] yes=25,no=26,missing=26\n",
      "\t\t\t\t\t25:leaf=-0.000000\n",
      "\t\t\t\t\t26:leaf=0.126531\n",
      "\t\t\t12:[f3<66.000000] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:[f1<0.000000] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=-0.000000\n",
      "\t\t\t\t\t28:leaf=0.054675\n",
      "\t\t\t\t20:[f0<491.000000] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=0.330918\n",
      "\t\t\t\t\t30:leaf=-0.067579\n",
      "Loss after Tree 4: 0.7111209596158269\n",
      "\n",
      "\n",
      "Tree 5:\n",
      "0:[f6<1.500000] yes=1,no=2,missing=2\n",
      "\t1:[f3<38.000000] yes=3,no=4,missing=4\n",
      "\t\t3:[f1<0.000000] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.000000\n",
      "\t\t\t8:[f1<0.000000] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=-0.000000\n",
      "\t\t\t\t14:[f1<0.000000] yes=21,no=22,missing=22\n",
      "\t\t\t\t\t21:leaf=-0.000000\n",
      "\t\t\t\t\t22:leaf=0.046451\n",
      "\t\t4:[f8<1.000000] yes=9,no=10,missing=10\n",
      "\t\t\t9:[f3<47.000000] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:[f1<1.000000] yes=23,no=24,missing=24\n",
      "\t\t\t\t\t23:leaf=0.102787\n",
      "\t\t\t\t\t24:leaf=0.229315\n",
      "\t\t\t\t16:[f9<141946.240000] yes=25,no=26,missing=26\n",
      "\t\t\t\t\t25:leaf=0.241587\n",
      "\t\t\t\t\t26:leaf=0.381356\n",
      "\t\t\t10:[f1<2.000000] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:[f1<1.000000] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=0.029312\n",
      "\t\t\t\t\t28:leaf=0.237602\n",
      "\t\t\t\t18:[f5<75836.465000] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=0.096498\n",
      "\t\t\t\t\t30:leaf=-0.060612\n",
      "\t2:[f6<2.000000] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=-0.000000\n",
      "\t\t6:[f6<2.000000] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.000000\n",
      "\t\t\t12:[f6<2.000000] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.000000\n",
      "\t\t\t\t20:[f6<2.000000] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=-0.000000\n",
      "\t\t\t\t\t32:leaf=0.001002\n",
      "Loss after Tree 5: 0.7125843029669914\n",
      "\n",
      "\n",
      "Model Accuracy: 0.856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Load the Customer dataset\n",
    "data = pd.read_csv('../data/Customer/Churn_Predictions.csv')\n",
    "data = data.drop(['RowNumber','CustomerId','Surname'],axis=1)\n",
    "\n",
    "# Create a sample dataframe with categorical data\n",
    "Genderr = pd.DataFrame({'Gender': ['Male', 'Female']})\n",
    "Geographyy = pd.DataFrame({'Geography': ['France', 'Germany','Spain']})  \n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical data\n",
    "data['Gender'] = le.fit_transform(data['Gender'])\n",
    "data['Geography'] = le.fit_transform(data['Geography'])\n",
    "\n",
    "# Data pre-processing\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "y = y.values if isinstance(y, pd.Series) else y\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the XGBoost model we implemented earlier and train it\n",
    "model = XGBoost(num_trees=5, max_depth=5, learning_rate=0.3)\n",
    "model.train(X_train, y_train, detailed='true')\n",
    "\n",
    "# Generates predictions on the test data.\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary labels (0 or 1) using a threshold of 0.5\n",
    "predictions = np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(\"Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.8560\n",
      "Fold 2 Accuracy: 0.8545\n",
      "Fold 3 Accuracy: 0.8505\n",
      "Fold 4 Accuracy: 0.8610\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define 5-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store accuracy for each fold\n",
    "accuracy_scores = []\n",
    "# Perform 5-Fold Cross-Validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    # Split data into train and test sets for this fold    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # Initialize and train the XGBoost model on the training data\n",
    "    model_x = XGBoost(num_trees=5, max_depth=5, learning_rate=0.3)\n",
    "    model_x.train(X_train, y_train, detailed=False)\n",
    "    \n",
    "    # Generate predictions on the test data\n",
    "    y_prob = model.predict(X_test)\n",
    "    \n",
    "    # Convert predictions to binary labels (0 or 1) using a threshold of 0.5\n",
    "    predictions = np.where(y_prob >= 0.5, 1, 0)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = np.mean(predictions == y_test)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(f'Fold {fold} Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy scores for each fold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), accuracy_scores, marker='o', linestyle='-', color='b', label='Fold Accuracy')\n",
    "plt.axhline(mean_accuracy, color='r', linestyle='--', label=f'Average Accuracy: {mean_accuracy:.4f}')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('5-Fold Cross-Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing with imported XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=5, max_depth=5, learning_rate=0.3, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "# Retrieve and print model parameters for reference\n",
    "params = model.get_params()\n",
    "print(params)\n",
    "n_estimators = params['n_estimators']\n",
    "max_depth = params['max_depth']\n",
    "learning_rate = params['learning_rate']\n",
    "\n",
    "print(\"Number of estimators:\", n_estimators)\n",
    "print(\"Max depth:\", max_depth)\n",
    "print(\"Learning rate:\", learning_rate)\n",
    "\n",
    "# Retrieve the trained booster (underlying model) from XGBoost\n",
    "booster = model.get_booster()\n",
    "\n",
    "# Iterate over each tree in the model and print its structure\n",
    "for i, tree in enumerate(booster.get_dump()):\n",
    "    print(f\"Tree {i + 1} structure:\\n{tree}\\n\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_s = model.predict(X_test)\n",
    "\n",
    "# Compute and print the accuracy score\n",
    "accuracy_s = accuracy_score(y_test, y_pred_s)\n",
    "print(\"Model Accuracy:\", accuracy_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define 5-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store accuracy for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform 5-Fold Cross-Validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Create an XGBoost model with log loss as the evaluation metric\n",
    "    model = xgb.XGBClassifier(n_estimators=5, max_depth=5, eval_metric='logloss')\n",
    "    \n",
    "    # Fits the XGBoost model to the training data.\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(f'Fold {fold} Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "mean_accuracy_s = np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy scores for each fold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), accuracy_scores, marker='o', linestyle='-', color='b', label='Fold Accuracy')\n",
    "plt.axhline(mean_accuracy_s, color='r', linestyle='--', label=f'Average Accuracy: {mean_accuracy_s:.4f}')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('5-Fold Cross-Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results 2\n",
    "\n",
    "From the comparison of the two figures, it can be seen that under the 5-fold experiment, our average accuracy is only 0.2% lower than the previous work. This shows that we successfully reproduced the previous work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work uses XGBoost to predict which passengers would survive the Titanic shipwreck. The dataset used is Titanic - Machine Learning from Disaster. Below are the features included in the dataset:\n",
    "\n",
    "| **Feature**   | **Description**                                       |\n",
    "|---------------|-------------------------------------------------------|\n",
    "| **PassengerId** | Unique identifier for each Passenger.                 |\n",
    "| **Survival**    | Survival status (0 = No, 1 = Yes).                    |\n",
    "| **Pclass**      | Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd).             |\n",
    "| **Sex**         | Sex of the passenger.                                 |\n",
    "| **Age**         | Age of the passenger in years.                        |\n",
    "| **Sibsp**       | Number of siblings/spouses aboard the Titanic.        |\n",
    "| **Parch**       | Number of parents/children aboard the Titanic.        |\n",
    "| **Ticket**      | Ticket number.                                        |\n",
    "| **Fare**        | Passenger fare.                                       |\n",
    "| **Cabin**       | Cabin number.                                         |\n",
    "| **Embarked**    | Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton). |\n",
    "\n",
    "To facilitate result comparison, we made the following improvements:\n",
    "\n",
    "- Remove the Name, PassengerId, Ticket columns as the irrelevant columns.\n",
    "- Count the null values in the Cabin and Age columns and set the number of null values into a new feature: 0 means no null values, 1 means one null value, and 2 means all values are nulls.\n",
    "- Extract the first letter of the Cabin code and map it to a number.\n",
    "- Fill the missing cells in Fare with the average ticket price of third-class passengers.\n",
    "- Fill the missing cells in Embarked with the Embarkation Southampton.\n",
    "- Convert the 'Sex', 'Nulls', 'Cabin_mapped', 'Embarked' columns into one-hot encodings.\n",
    "- Set the number of decision trees used by XGBoost to 5, the maximum depth of the trees to 5, and the learning rate to 0.3.\n",
    "\n",
    "We split the dataset into 20% training and 80% testing sets, using 5-fold cross-validation to evaluate the accuracy of our model and the previous work's model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing with OUR XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "train = pd.read_csv('../data/Titanic/train.csv')\n",
    "test = pd.read_csv('../data/Titanic/test.csv')\n",
    "\n",
    "# Concatenate training set and test set\n",
    "X_full = pd.concat([train.drop('Survived', axis = 1), test], axis = 0)\n",
    "\n",
    "# Clean X_full\n",
    "X_full.drop('PassengerId', axis = 1, inplace=True)\n",
    "X_full['Nulls'] = X_full.Cabin.isnull().astype('int') + X_full.Age.isnull().astype('int')\n",
    "\n",
    "# Divide the cabin category by simply extracting the first letter\n",
    "X_full['Cabin_mapped'] = X_full['Cabin'].astype(str).str[0]\n",
    "cabin_dict = {k:i for i, k in enumerate(X_full.Cabin_mapped.unique())} \n",
    "\n",
    "# Transform 'Age' and 'Cabin'\n",
    "X_full.loc[:, 'Cabin_mapped'] = X_full.loc[:, 'Cabin_mapped'].map(cabin_dict)\n",
    "X_full.drop(['Age', 'Cabin'], inplace = True, axis = 1)\n",
    "\n",
    "# Assume people with missing fare paid the average price\n",
    "fare_mean = X_full[X_full.Pclass == 3].Fare.mean()\n",
    "X_full['Fare'].fillna(fare_mean, inplace = True)\n",
    "X_full['Embarked'].fillna('S', inplace = True)\n",
    "\n",
    "# Fit and transform the categorical data\n",
    "X_full.drop(['Name', 'Ticket'], axis = 1, inplace = True)\n",
    "X_dummies = pd.get_dummies(X_full, columns = ['Sex', 'Nulls', 'Cabin_mapped', 'Embarked'], drop_first= True)\n",
    "\n",
    "# Split and construct desired dataset\n",
    "X = X_dummies[:len(train)]; new_X = X_dummies[len(train):]\n",
    "y = train.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "model = XGBoost(num_trees=5, max_depth=5, learning_rate=0.3)\n",
    "\n",
    "# Trains the XGBoost model on the training data.\n",
    "X_train = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
    "X_test = X_test.values if isinstance(X_test, pd.DataFrame) else X_test\n",
    "y_train = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "y_test = y_test.values if isinstance(y_test, pd.Series) else y_test\n",
    "model.train(X_train, y_train, detailed='true')\n",
    "\n",
    "# Generates predictions on the test data.\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary labels (0 or 1) using a threshold of 0.5\n",
    "predictions = np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(\"Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# Define 5-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store accuracy for each fold\n",
    "accuracy_scores = []\n",
    "#Perform 5-Fold Cross-Validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "    y = y.values if isinstance(y, pd.Series) else y\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #Create an XGBoost model with log loss as the evaluation metric\n",
    "    model_x = XGBoost(num_trees=5, max_depth=5, learning_rate=0.3)\n",
    "    model_x.train(X_train, y_train, detailed=False)\n",
    "    # Generate predictions\n",
    "    y_prob = model.predict(X_test)\n",
    "    predictions = np.where(y_prob >= 0.5, 1, 0)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = np.mean(predictions == y_test)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(f'Fold {fold} Accuracy: {accuracy:.8f}')\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "mean_accuracy_s = np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), accuracy_scores, marker='o', linestyle='-', color='b', label='Fold Accuracy')\n",
    "plt.axhline(mean_accuracy_s, color='r', linestyle='--', label=f'Average Accuracy: {mean_accuracy_s:.4f}')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('5-Fold Cross-Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing with imported XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=5, max_depth=5, learning_rate=0.3, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "params = model.get_params()\n",
    "print(params)\n",
    "n_estimators = params['n_estimators']\n",
    "max_depth = params['max_depth']\n",
    "learning_rate = params['learning_rate']\n",
    "\n",
    "print(\"Number of estimators:\", n_estimators)\n",
    "print(\"Max depth:\", max_depth)\n",
    "print(\"Learning rate:\", learning_rate)\n",
    "\n",
    "# Retrieve the trained booster (underlying model) from XGBoost\n",
    "booster = model.get_booster()\n",
    "\n",
    "# Iterate over each tree in the model and print its structure\n",
    "for i, tree in enumerate(booster.get_dump()):\n",
    "    print(f\"Tree {i + 1} structure:\\n{tree}\\n\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_s = model.predict(X_test)\n",
    "\n",
    "# Compute and print the accuracy score\n",
    "accuracy_s = accuracy_score(y_test, y_pred_s)\n",
    "print(\"Model Accuracy:\", accuracy_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define 5-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store accuracy for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform 5-Fold Cross-Validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Create an XGBoost model with log loss as the evaluation metric\n",
    "    model = xgb.XGBClassifier(n_estimators=5, max_depth=5, eval_metric='logloss')\n",
    "    \n",
    "    # Fits the XGBoost model to the training data.\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(f'Fold {fold} Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "mean_accuracy_s = np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy scores for each fold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), accuracy_scores, marker='o', linestyle='-', color='b', label='Fold Accuracy')\n",
    "plt.axhline(mean_accuracy_s, color='r', linestyle='--', label=f'Average Accuracy: {mean_accuracy_s:.4f}')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('5-Fold Cross-Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results 3\n",
    "\n",
    "From the comparison of the two figures, it can be seen that under the 5-fold experiment, our average accuracy is 2.8% lower than the previous work. This shows that we successfully reproduced the previous work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation and Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Chen, T. & Guestrin, C. (2016) 'XGBoost: A scalable tree boosting system', *Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*. ACM. Available at: https://doi.org/10.1145/2939672.2939785 (Accessed: 28 November 2024).\n",
    "\n",
    "2. Friedman, J.H. (2001) 'Greedy function approximation: A gradient boosting machine', *Annals of Statistics*, 29(5), pp. 1189–1232. Available at: https://doi.org/10.1214/aos/1013203451 (Accessed: 28 November 2024).\n",
    "\n",
    "3. Hastie, T., Tibshirani, R. & Friedman, J. (2009) *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*. 2nd edn. Springer Science & Business Media. Available at: https://doi.org/10.1007/978-0-387-84858-7 (Accessed: 28 November 2024).\n",
    "\n",
    "4. Bishop, C.M. (2006) *Pattern Recognition and Machine Learning*. 1st edn. Springer. Available at: https://doi.org/10.1007/978-0-387-45528-0 (Accessed: 28 November 2024).\n",
    "\n",
    "5. Quinlan, J.R. (1996) 'Bagging, boosting, and C4.5', *Proceedings of the National Conference on Artificial Intelligence*, pp. 725–730. Available at: https://www.aaai.org/Papers/AAAI/1996/AAAI96-108.pdf (Accessed: 28 November 2024).\n",
    "\n",
    "6. Breiman, L. (1996) 'Bagging predictors', *Machine Learning*, 24(2), pp. 123–140. Available at: https://doi.org/10.1007/BF00058655 (Accessed: 28 November 2024).\n",
    "\n",
    "7. Chen, T., He, T., Benesty, M., Khotilovich, V. & Tang, Y. (2020) *XGBoost: Extreme Gradient Boosting*. R Package version 1.4.1. Available at: https://xgboost.readthedocs.io/ (Accessed: 28 November 2024).\n",
    "\n",
    "8. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., & Duchesnay, E. (2011) Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12, pp.2825-2830. Available at: http://jmlr.org/papers/v12/pedregosa11a.html (Accessed: 28 November 2024).\n",
    "\n",
    "9. Breast Cancer Wisconsin (Diagnostic) Data Set: Kaggle (n.d.) 'Breast Cancer Wisconsin (Diagnostic) Data Set'. Available at: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data (Accessed: 4 December 2024).\n",
    "\n",
    "10. Customer Exited Prediction | XGBoost: Ezzeldean, M. (n.d.) 'Customer Exited Prediction | XGBoost'. Kaggle. Available at: https://www.kaggle.com/code/mohammedezzeldean/customer-exited-prediction-xgboost/notebook (Accessed: 4 December 2024).\n",
    "\n",
    "11. Titanic - Machine Learning from Disaster: Kaggle (n.d.) 'Titanic - Machine Learning from Disaster'. Available at: https://www.kaggle.com/c/titanic/overview (Accessed: 4 December 2024).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

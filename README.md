# XGBoost Algorithm Overview

XGBoost, or Extreme Gradient Boosting, is an efficient, scalable machine learning algorithm used primarily for supervised learning tasks like classification and regression. It builds upon gradient boosting principles to create an ensemble of weak learners that sequentially correct the errors of previous models to improve accuracy.

## How XGBoost Works

1. **Initialization**:
   - Starts with an initial prediction (average value for regression or a default probability for classification).

2. **Iterative Model Training**:
   - In each step, a new weak learner (we are using decision tree) is trained to minimize residual errors from previous models. 
   - The weak learner is trained on a modified dataset where the target is now the residual error from the last iteration.

3. **Gradient Boosting with Regularization**:
   
   - XGBoost includes regularization terms in the objective function to control overfitting:

     $\text{Objective} = \sum_{i=1}^{n} L(y_i, \hat{y}\_i) + \sum_{k=1}^{K} \Omega(f_k)$
     
     where $L(y_i, \hat{y}_i)$ is the loss function, and $\Omega(f_k)$ is the regularization term for tree $f_k$.
   
4. **Shrinking (Learning Rate)**:
   - Applies a learning rate to scale each weak learnerâ€™s contribution, ensuring gradual model improvement to prevent overfitting.
   
5. **Tree Pruning**:
   - Uses constraints like "max depth" to limit tree depth, preventing overfitting.
   
6. **Weighted Data and Column Sampling**:
   - Row and column sampling prevent overfitting, making the model more robust to noisy data.
   
7. **Final Prediction**:
   - Predictions are generated by aggregating the outputs of all weak learners, often by summing their outputs.

## Representation and Optimizer of XGBoost

Please refer to XGBoost_Report.ipynb for detailed introduction to the representation and optimizer of XGboost.
## Prerequisites

You can recreate the python environment using the `BYD2060-XGBoost.yml` conda environment file by running these two commands in the terminal:

`conda env create -n BYD2060-XGBoost -f BYD2060-XGBoost.yml`

`conda activate BYD2060-XGBoost`

Then you are able to run our .ipynb files now. 

## Author
*Sort by first letter of surname
  
Yanshu Li (yanshu_li1@brown.edu)

Xinye Yang(xinye_yang@brown.edu)

Ziqi Zhang(zzhan360@cs.brown.edu)

Jiayi Zhou(jiayi_zhou@brown.edu)

## License

This project is licensed under the Apache-2.0 License.

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\" A class representing a decision tree model used in gradient boosting.\n",
    "\n",
    "    Attributes:\n",
    "        max_depth (int): Maximum depth of the tree.\n",
    "        min_samples_split (int): Minimum number of samples required to split a node.\n",
    "        tree (dict or float): The root of the tree, represented as a dictionary or a leaf value.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_depth=3, min_samples_split=2):\n",
    "        \"\"\" Initializes the DecisionTree with maximum depth and minimum samples required to split.\n",
    "\n",
    "        @params:\n",
    "            max_depth (int): The maximum depth of the tree. Default is 3.\n",
    "            min_samples_split (int): Minimum samples required to split a node. Default is 2.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def train(self, X, y, grad, hess):\n",
    "        \"\"\" Trains the decision tree using the given data, gradients, and hessians.\n",
    "\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with training data.\n",
    "            y (numpy.ndarray): A 1D array of shape (n_samples,) with target values.\n",
    "            grad (numpy.ndarray): A 1D array of gradients for each sample.\n",
    "            hess (numpy.ndarray): A 1D array of hessians for each sample.\n",
    "        \"\"\"\n",
    "        self.tree = self._build_tree(X, y, grad, hess)\n",
    "\n",
    "    def _split(self, X, y, grad, hess):\n",
    "        \"\"\" Finds the best split for the data to maximize the gain.\n",
    "\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with training data.\n",
    "            y (numpy.ndarray): A 1D array of shape (n_samples,) with target values.\n",
    "            grad (numpy.ndarray): A 1D array of gradients for each sample.\n",
    "            hess (numpy.ndarray): A 1D array of hessians for each sample.\n",
    "        @return:\n",
    "            tuple: The best feature index and threshold for the split.\n",
    "        \"\"\"\n",
    "        best_gain = -np.inf\n",
    "        best_split = None\n",
    "        # Iterate over all features to find the best split point\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature_index])  # Unique thresholds for the feature\n",
    "            for threshold in thresholds:\n",
    "                left_mask = X[:, feature_index] < threshold\n",
    "                right_mask = ~left_mask\n",
    "                if sum(left_mask) >= self.min_samples_split and sum(right_mask) >= self.min_samples_split:\n",
    "                    gain = self._gain(y, grad, hess, left_mask, right_mask)\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_split = (feature_index, threshold)\n",
    "        return best_split\n",
    "\n",
    "    def _gain(self, y, grad, hess, left_mask, right_mask):\n",
    "        \"\"\" Calculates the gain of the proposed split.\n",
    "\n",
    "        @params:\n",
    "            y (numpy.ndarray): A 1D array of target values.\n",
    "            grad (numpy.ndarray): A 1D array of gradients for each sample.\n",
    "            hess (numpy.ndarray): A 1D array of hessians for each sample.\n",
    "            left_mask (numpy.ndarray): A boolean mask for the left split.\n",
    "            right_mask (numpy.ndarray): A boolean mask for the right split.\n",
    "        @return:\n",
    "            float: The calculated gain for the split.\n",
    "        \"\"\"\n",
    "        # Compute sums of gradients and hessians for the left and right splits\n",
    "        grad_left, grad_right = grad[left_mask], grad[right_mask]\n",
    "        hess_left, hess_right = hess[left_mask], hess[right_mask]\n",
    "        G_L, H_L = np.sum(grad_left), np.sum(hess_left)\n",
    "        G_R, H_R = np.sum(grad_right), np.sum(hess_right)\n",
    "        # Calculate the gain using the formula\n",
    "        gain = 0.5 * ((G_L ** 2) / (H_L + 1e-10) + (G_R ** 2) / (H_R + 1e-10) - ((G_L + G_R) ** 2) / (H_L + H_R + 1e-10))\n",
    "        return gain\n",
    "\n",
    "    def _build_tree(self, X, y, grad, hess, depth=0):\n",
    "        \"\"\" Recursively builds the decision tree based on the provided data.\n",
    "\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with training data.\n",
    "            y (numpy.ndarray): A 1D array of target values.\n",
    "            grad (numpy.ndarray): A 1D array of gradients for each sample.\n",
    "            hess (numpy.ndarray): A 1D array of hessians for each sample.\n",
    "            depth (int): The current depth of the tree.\n",
    "        @return:\n",
    "            dict or float: A dictionary representing the subtree or a leaf value.\n",
    "        \"\"\"\n",
    "        if depth == self.max_depth or len(y) < self.min_samples_split:\n",
    "            # Return leaf value if maximum depth is reached or samples are insufficient\n",
    "            leaf_value = -np.sum(grad) / (np.sum(hess) + 1e-10)\n",
    "            return leaf_value\n",
    "\n",
    "        best_split = self._split(X, y, grad, hess)\n",
    "        if not best_split:\n",
    "            # Return leaf value if no valid split is found\n",
    "            return -np.sum(grad) / (np.sum(hess) + 1e-10)\n",
    "\n",
    "        feature_index, threshold = best_split\n",
    "        left_mask = X[:, feature_index] < threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        # Recursively build left and right subtrees\n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask], grad[left_mask], hess[left_mask], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask], grad[right_mask], hess[right_mask], depth + 1)\n",
    "        return {\"feature_index\": feature_index, \"threshold\": threshold, \"left\": left_subtree, \"right\": right_subtree}\n",
    "\n",
    "    def _predict(self, x, tree):\n",
    "        \"\"\" Predicts the value for a single sample using the decision tree.\n",
    "\n",
    "        @params:\n",
    "            x (numpy.ndarray): A 1D array of feature values for a single sample.\n",
    "            tree (dict or float): The decision tree or leaf value to predict with.\n",
    "        @return:\n",
    "            float: The predicted value for the sample.\n",
    "        \"\"\"\n",
    "        if not isinstance(tree, dict):\n",
    "            # Return the leaf value if the node is a leaf\n",
    "            return tree\n",
    "\n",
    "        feature_index = tree[\"feature_index\"]\n",
    "        threshold = tree[\"threshold\"]\n",
    "        # Traverse left or right subtree based on the feature value\n",
    "        if x[feature_index] < threshold:\n",
    "            return self._predict(x, tree[\"left\"])\n",
    "        else:\n",
    "            return self._predict(x, tree[\"right\"])\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predicts the values for multiple samples using the decision tree.\n",
    "\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with input data.\n",
    "        @return:\n",
    "            numpy.ndarray: A 1D array of predicted values for each sample.\n",
    "        \"\"\"\n",
    "        return np.array([self._predict(x, self.tree) for x in X])\n",
    "\n",
    "    def print_tree(self, tree=None, depth=0):\n",
    "        \"\"\" Prints the structure of the decision tree.\n",
    "\n",
    "        @params:\n",
    "            tree (dict or float, optional): The tree to print. If None, use the root tree.\n",
    "            depth (int): The current depth in the tree for formatting purposes.\n",
    "        \"\"\"\n",
    "        if tree is None:\n",
    "            tree = self.tree\n",
    "\n",
    "        indent = \"\\t\" * depth  # Increase indentation based on the depth\n",
    "        if not isinstance(tree, dict):  # If the node is a leaf\n",
    "            print(f\"{indent}{tree:.4f}\")  # Print the leaf value\n",
    "        else:  # If the node is not a leaf\n",
    "            feature_index = tree[\"feature_index\"]\n",
    "            threshold = tree[\"threshold\"]\n",
    "            # Print the splitting condition\n",
    "            print(f\"{indent}{depth}:[f{feature_index}<{threshold:.8f}] yes={depth + 1},no={depth + 2},missing={depth + 2}\")\n",
    "            print(f\"{indent}\\tyes->\")\n",
    "            self.print_tree(tree[\"left\"], depth + 1)\n",
    "            print(f\"{indent}\\tno->\")\n",
    "            self.print_tree(tree[\"right\"], depth + 1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost:\n",
    "    \"\"\" A simple implementation of XGBoost for binary classification.\n",
    "\n",
    "    Attributes:\n",
    "        n_estimators (int): Number of boosting rounds (trees).\n",
    "        max_depth (int): Maximum depth of each decision tree.\n",
    "        min_samples_split (int): Minimum number of samples required to split an internal node.\n",
    "        learning_rate (float): Step size shrinkage used in update to prevent overfitting.\n",
    "        trees (list): List of trained decision tree models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=10, max_depth=3, min_samples_split=2, learning_rate=0.1):\n",
    "        \"\"\" Initializes the XGBoost model with the specified parameters.\n",
    "\n",
    "        @params:\n",
    "            n_estimators (int): Number of trees to fit. Default is 10.\n",
    "            max_depth (int): Maximum depth of each tree. Default is 3.\n",
    "            min_samples_split (int): Minimum samples required to split a node. Default is 2.\n",
    "            learning_rate (float): Learning rate for the model. Default is 0.1.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.learning_rate = learning_rate\n",
    "        self.trees = []\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\" Trains the XGBoost model using the training data.\n",
    "\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with the training data.\n",
    "            y (numpy.ndarray): A 1D array of shape (n_samples,) with the target labels.\n",
    "        \"\"\"\n",
    "        # Initialize predictions with zeros\n",
    "        y_pred = np.zeros_like(y, dtype=float)\n",
    "\n",
    "        # Train each tree iteratively\n",
    "        for i in range(self.n_estimators):\n",
    "            # Compute gradients and hessians\n",
    "            grad, hess = self._compute_gradients(y, y_pred)\n",
    "            \n",
    "            # Initialize and train a new decision tree\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.train(X, y, grad, hess)\n",
    "            \n",
    "            # Make predictions using the trained tree\n",
    "            predictions = tree.predict(X)\n",
    "            \n",
    "            # Update predictions with the learning rate\n",
    "            y_pred += self.learning_rate * predictions\n",
    "            self.trees.append(tree)  # Store the trained tree\n",
    "            \n",
    "            # Print the structure of the current tree\n",
    "            print(f\"Tree {i + 1}:\")\n",
    "            tree.print_tree()\n",
    "\n",
    "            # Calculate and print the cross-entropy loss\n",
    "            loss = self._cross_entropy_loss(y, 1 / (1 + np.exp(-y_pred)))  # Apply sigmoid to get probabilities\n",
    "            print(f\"Loss after Tree {i + 1}: {loss}\")\n",
    "            \n",
    "            print(\"\\n\")\n",
    "\n",
    "    def _compute_gradients(self, y, y_pred):\n",
    "        \"\"\" Computes the gradients and hessians for the loss function.\n",
    "\n",
    "        @params:\n",
    "            y (numpy.ndarray): A 1D array of target labels.\n",
    "            y_pred (numpy.ndarray): A 1D array of current predictions.\n",
    "        @return:\n",
    "            tuple: A tuple containing:\n",
    "                - grad (numpy.ndarray): A 1D array of gradients for each sample.\n",
    "                - hess (numpy.ndarray): A 1D array of hessians for each sample.\n",
    "        \"\"\"\n",
    "        # Compute the first derivative (gradient)\n",
    "        grad = y_pred - y\n",
    "        \n",
    "        # For the squared error loss, the second derivative (hessian) is constant and equal to 1\n",
    "        hess = np.ones_like(y)\n",
    "        return grad, hess\n",
    "\n",
    "    def _cross_entropy_loss(self, y, y_pred):\n",
    "        \"\"\" Computes the cross-entropy loss between true and predicted labels.\n",
    "\n",
    "        @params:\n",
    "            y (numpy.ndarray): A 1D array of target labels.\n",
    "            y_pred (numpy.ndarray): A 1D array of predicted probabilities.\n",
    "        @return:\n",
    "            float: The mean cross-entropy loss.\n",
    "        \"\"\"\n",
    "        # Clip predicted probabilities to avoid log(0)\n",
    "        y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
    "        loss = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Outputs predicted labels for the input data using the trained trees.\n",
    "\n",
    "        @params:\n",
    "            X (numpy.ndarray): A 2D array of shape (n_samples, n_features) with the input data.\n",
    "        @return:\n",
    "            numpy.ndarray: A 1D array of predicted values for each sample.\n",
    "        \"\"\"\n",
    "        # Initialize predictions with zeros\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "\n",
    "        # Aggregate predictions from each tree\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 1:\n",
      "0:[f7<0.07482458] yes=1,no=2,missing=2\n",
      "\tyes->\n",
      "\t1:[f20<0.12855895] yes=2,no=3,missing=3\n",
      "\t\tyes->\n",
      "\t\t2:[f10<0.86558942] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f24<1.94769028] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f14<-1.23437635] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.1429\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.0040\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t0.5000\n",
      "\t\t\tno->\n",
      "\t\t\t0.6667\n",
      "\t\tno->\n",
      "\t\t2:[f1<-0.60728273] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f0<0.32454537] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t-0.0000\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f0<0.61707999] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t-0.0000\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t-0.0000\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f17<-0.23782161] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f0<0.26206224] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t1.0000\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t1.0000\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t-0.0000\n",
      "\tno->\n",
      "\t1:[f27<0.48715636] yes=2,no=3,missing=3\n",
      "\t\tyes->\n",
      "\t\t2:[f22<0.26624928] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f1<0.47945762] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f0<-1.01032135] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t-0.0000\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t-0.0000\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f0<0.13425586] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t1.0000\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t1.0000\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f0<0.70228425] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t1.0000\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f0<0.93517589] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t1.0000\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t1.0000\n",
      "\t\tno->\n",
      "\t\t2:[f16<3.70053211] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f0<-0.66098389] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t1.0000\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f0<-0.47637467] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t1.0000\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t1.0000\n",
      "\t\t\tno->\n",
      "\t\t\t-0.0000\n",
      "Loss after Tree 1: 0.6435127119020766\n",
      "\n",
      "\n",
      "Tree 2:\n",
      "0:[f27<0.42320465] yes=1,no=2,missing=2\n",
      "\tyes->\n",
      "\t1:[f23<0.15191332] yes=2,no=3,missing=3\n",
      "\t\tyes->\n",
      "\t\t2:[f1<0.74008914] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f10<0.86558942] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f19<-0.92705768] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.1053\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t-0.0022\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t0.2000\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f20<0.11820482] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f1<0.78895755] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.8494\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.0471\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f0<0.28478338] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.7000\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.7000\n",
      "\t\tno->\n",
      "\t\t2:[f26<-0.37894911] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f0<0.91529490] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t-0.0000\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t0.3500\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f4<0.06047061] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f0<1.08570341] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.7000\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.7000\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t0.7000\n",
      "\tno->\n",
      "\t1:[f2<-0.82664750] yes=2,no=3,missing=3\n",
      "\t\tyes->\n",
      "\t\t2:[f5<1.05292554] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t-0.0012\n",
      "\t\t\tno->\n",
      "\t\t\t-0.0000\n",
      "\t\tno->\n",
      "\t\t2:[f11<-1.34470720] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t-0.0006\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f6<-0.02384586] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f8<-0.02051330] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.7000\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t-0.0006\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f16<3.17996685] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.7011\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.3500\n",
      "Loss after Tree 2: 0.61382169576266\n",
      "\n",
      "\n",
      "Tree 3:\n",
      "0:[f7<0.07482458] yes=1,no=2,missing=2\n",
      "\tyes->\n",
      "\t1:[f20<0.12855895] yes=2,no=3,missing=3\n",
      "\t\tyes->\n",
      "\t\t2:[f10<0.86558942] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f21<2.22489838] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f14<-1.23437635] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.0960\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t-0.0006\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t0.2030\n",
      "\t\t\tno->\n",
      "\t\t\t0.4220\n",
      "\t\tno->\n",
      "\t\t2:[f1<-0.60728273] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f0<0.61707999] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f0<0.32454537] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.0006\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.0006\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t-0.0522\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f17<-0.23782161] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f9<-1.35347305] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.5425\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.4900\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t-0.0000\n",
      "\tno->\n",
      "\t1:[f22<0.21859193] yes=2,no=3,missing=3\n",
      "\t\tyes->\n",
      "\t\t2:[f21<0.02650719] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f27<0.90588779] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f24<-1.29616567] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t-0.0825\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.0005\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t0.4897\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f12<-0.62574801] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t0.2451\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f4<-0.31030134] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.5879\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.4873\n",
      "\t\tno->\n",
      "\t\t2:[f14<5.42989385] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f27<0.42472731] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f0<0.81873007] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.4900\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.4900\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f6<-0.02384586] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.4900\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.4897\n",
      "\t\t\tno->\n",
      "\t\t\t0.5425\n",
      "Loss after Tree 3: 0.5949167203973544\n",
      "\n",
      "\n",
      "Tree 4:\n",
      "0:[f27<0.42320465] yes=1,no=2,missing=2\n",
      "\tyes->\n",
      "\t1:[f23<0.15191332] yes=2,no=3,missing=3\n",
      "\t\tyes->\n",
      "\t\t2:[f1<0.53298017] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f10<1.17634240] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f10<0.50899947] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t-0.0030\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.3069\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t-0.2109\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f18<-0.74127877] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f17<-0.79728274] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.1639\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.7780\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f7<0.09778122] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.0187\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.3740\n",
      "\t\tno->\n",
      "\t\t2:[f26<-0.37894911] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f1<0.03964194] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t-0.0447\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t0.2161\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f8<-0.95515481] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t0.3351\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f4<0.06047061] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.3430\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.3430\n",
      "\tno->\n",
      "\t1:[f16<3.70053211] yes=2,no=3,missing=3\n",
      "\t\tyes->\n",
      "\t\t2:[f11<-1.34470720] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t-0.0004\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f20<-0.28146446] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f4<0.90662772] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t-0.0370\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.3435\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f26<-0.20335975] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.1710\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.3457\n",
      "\t\tno->\n",
      "\t\t2:[f8<1.37414708] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t-0.0404\n",
      "\t\t\tno->\n",
      "\t\t\t-0.0002\n",
      "Loss after Tree 4: 0.5822573940429641\n",
      "\n",
      "\n",
      "Tree 5:\n",
      "0:[f27<0.42320465] yes=1,no=2,missing=2\n",
      "\tyes->\n",
      "\t1:[f20<0.11820482] yes=2,no=3,missing=3\n",
      "\t\tyes->\n",
      "\t\t2:[f10<0.86558942] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f26<-0.30554700] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f14<-1.23437635] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t-0.0701\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t-0.0048\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f15<-0.71081092] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.7010\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.0058\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f4<-0.17722196] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t-0.1476\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t0.4736\n",
      "\t\tno->\n",
      "\t\t2:[f1<-0.60728273] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t3:[f1<-1.24722618] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t-0.0373\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f0<0.58015814] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.0014\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.0093\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f11<0.81672069] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f14<0.07200995] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.2602\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.1516\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t0.0809\n",
      "\tno->\n",
      "\t1:[f16<3.70053211] yes=2,no=3,missing=3\n",
      "\t\tyes->\n",
      "\t\t2:[f11<-1.34470720] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t-0.0003\n",
      "\t\t\tno->\n",
      "\t\t\t3:[f20<-0.28146446] yes=4,no=5,missing=5\n",
      "\t\t\t\tyes->\n",
      "\t\t\t\t4:[f4<0.90662772] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t-0.0259\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.2404\n",
      "\t\t\t\tno->\n",
      "\t\t\t\t4:[f6<-0.18643273] yes=5,no=6,missing=6\n",
      "\t\t\t\t\tyes->\n",
      "\t\t\t\t\t0.0936\n",
      "\t\t\t\t\tno->\n",
      "\t\t\t\t\t0.2424\n",
      "\t\tno->\n",
      "\t\t2:[f0<-1.01032135] yes=3,no=4,missing=4\n",
      "\t\t\tyes->\n",
      "\t\t\t0.0057\n",
      "\t\t\tno->\n",
      "\t\t\t-0.0341\n",
      "Loss after Tree 5: 0.5732002145373913\n",
      "\n",
      "\n",
      "Model Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset from a CSV file using numpy's genfromtxt\n",
    "data = np.genfromtxt('breast+cancer+wisconsin+diagnostic/wdbc.data', delimiter=',', dtype=str)\n",
    "\n",
    "# Extract features and convert them to float\n",
    "X = data[:, 2:].astype(float)  # Features start from the 3rd column (index 2)\n",
    "# Convert the labels to binary (Malignant -> 1, Benign -> 0)\n",
    "y = np.where(data[:, 1] == 'M', 1, 0)\n",
    "\n",
    "# Normalize the features using mean and standard deviation\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the XGBoost model we implemented earlier\n",
    "model = XGBoost(n_estimators=5, max_depth=5, learning_rate=0.3)\n",
    "\n",
    "# Trains the XGBoost model on the training data.\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# Generates predictions on the test data.\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary labels (0 or 1) using a threshold of 0.5\n",
    "predictions = np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of xgboost in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimators: None\n",
      "Max depth: None\n",
      "Learning rate: None\n",
      "Tree 1 structure:\n",
      "0:[f27<0.42320466] yes=1,no=2,missing=2\n",
      "\t1:[f23<0.151913315] yes=3,no=4,missing=4\n",
      "\t\t3:[f13<0.0616690516] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f1<0.740089118] yes=11,no=12,missing=12\n",
      "\t\t\t\t11:leaf=-0.466026366\n",
      "\t\t\t\t12:[f22<-0.20734556] yes=13,no=14,missing=14\n",
      "\t\t\t\t\t13:leaf=-0.357332468\n",
      "\t\t\t\t\t14:leaf=0.156942263\n",
      "\t\t\t8:leaf=0.0610413142\n",
      "\t\t4:[f26<-0.377509862] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=0.0178343765\n",
      "\t\t\t10:leaf=0.624066651\n",
      "\t2:[f20<-0.293889403] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=-0.035497915\n",
      "\t\t6:leaf=0.752050877\n",
      "\n",
      "\n",
      "Tree 2 structure:\n",
      "0:[f7<0.046967078] yes=1,no=2,missing=2\n",
      "\t1:[f20<0.118204817] yes=3,no=4,missing=4\n",
      "\t\t3:[f12<0.613808632] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f14<-1.23437631] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=-0.114261463\n",
      "\t\t\t\t14:[f24<1.49618065] yes=17,no=18,missing=18\n",
      "\t\t\t\t\t17:leaf=-0.403840512\n",
      "\t\t\t\t\t18:leaf=-0.0984430537\n",
      "\t\t\t8:leaf=0.0410378166\n",
      "\t\t4:[f1<-0.230297849] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.182360739\n",
      "\t\t\t10:leaf=0.395994633\n",
      "\t2:[f22<0.218591928] yes=5,no=6,missing=6\n",
      "\t\t5:[f21<-0.0321165733] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f4<1.56846631] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.365916401\n",
      "\t\t\t\t16:leaf=0.00907746423\n",
      "\t\t\t12:leaf=0.470775664\n",
      "\t\t6:leaf=0.524210393\n",
      "\n",
      "\n",
      "Tree 3 structure:\n",
      "0:[f7<0.046967078] yes=1,no=2,missing=2\n",
      "\t1:[f20<0.118204817] yes=3,no=4,missing=4\n",
      "\t\t3:[f12<0.613808632] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f21<1.25272095] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:[f19<-0.927435935] yes=23,no=24,missing=24\n",
      "\t\t\t\t\t23:leaf=-0.10368415\n",
      "\t\t\t\t\t24:leaf=-0.370571643\n",
      "\t\t\t\t16:[f1<1.82915652] yes=25,no=26,missing=26\n",
      "\t\t\t\t\t25:leaf=0.0561646484\n",
      "\t\t\t\t\t26:leaf=-0.241992071\n",
      "\t\t\t8:leaf=0.0343015306\n",
      "\t\t4:[f1<-0.82835412] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.215078056\n",
      "\t\t\t10:[f20<0.372916341] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=0.361676097\n",
      "\t\t\t\t18:leaf=0.0599818453\n",
      "\t2:[f22<-0.150752455] yes=5,no=6,missing=6\n",
      "\t\t5:[f21<-0.0321165733] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.270020843\n",
      "\t\t\t12:leaf=0.190431967\n",
      "\t\t6:[f21<-1.04011965] yes=13,no=14,missing=14\n",
      "\t\t\t13:[f7<0.954141438] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.247036889\n",
      "\t\t\t\t20:leaf=0.248852536\n",
      "\t\t\t14:[f16<2.24493885] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:leaf=0.433617115\n",
      "\t\t\t\t22:leaf=0.118983932\n",
      "\n",
      "\n",
      "Tree 4 structure:\n",
      "0:[f7<0.046967078] yes=1,no=2,missing=2\n",
      "\t1:[f20<0.118204817] yes=3,no=4,missing=4\n",
      "\t\t3:[f13<0.0533084013] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f14<-1.23437631] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.05130082\n",
      "\t\t\t\t16:[f21<1.22666597] yes=21,no=22,missing=22\n",
      "\t\t\t\t\t21:leaf=-0.344956666\n",
      "\t\t\t\t\t22:[f13<-0.494534165] yes=23,no=24,missing=24\n",
      "\t\t\t\t\t\t23:leaf=-0.229496703\n",
      "\t\t\t\t\t\t24:leaf=0.0750683919\n",
      "\t\t\t8:leaf=0.0472804122\n",
      "\t\t4:[f1<0.0582584739] yes=9,no=10,missing=10\n",
      "\t\t\t9:[f0<0.4353109] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=0.0581673197\n",
      "\t\t\t\t18:leaf=-0.229364052\n",
      "\t\t\t10:leaf=0.320933908\n",
      "\t2:[f27<0.487156361] yes=5,no=6,missing=6\n",
      "\t\t5:[f21<-0.455510437] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.270272046\n",
      "\t\t\t12:[f0<-0.166799188] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.11168804\n",
      "\t\t\t\t20:leaf=0.32427609\n",
      "\t\t6:[f19<2.10803103] yes=13,no=14,missing=14\n",
      "\t\t\t13:leaf=0.381736666\n",
      "\t\t\t14:leaf=0.0144605841\n",
      "\n",
      "\n",
      "Tree 5 structure:\n",
      "0:[f22<-0.165645376] yes=1,no=2,missing=2\n",
      "\t1:[f7<0.200441271] yes=3,no=4,missing=4\n",
      "\t\t3:[f13<-0.00543616246] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.320411235\n",
      "\t\t\t8:leaf=0.0600373857\n",
      "\t\t4:leaf=0.0861860961\n",
      "\t2:[f26<-0.305546999] yes=5,no=6,missing=6\n",
      "\t\t5:[f1<0.00473592943] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.25152719\n",
      "\t\t\t10:leaf=0.0500616021\n",
      "\t\t6:[f21<-0.986381173] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f7<0.396991432] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=-0.231403232\n",
      "\t\t\t\t14:leaf=0.153383717\n",
      "\t\t\t12:[f24<-1.2961657] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.0426249802\n",
      "\t\t\t\t16:leaf=0.347091526\n",
      "\n",
      "\n",
      "Tree 6 structure:\n",
      "0:[f23<-0.00717778318] yes=1,no=2,missing=2\n",
      "\t1:[f27<0.665307522] yes=3,no=4,missing=4\n",
      "\t\t3:[f21<0.723478615] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f28<-1.47825623] yes=11,no=12,missing=12\n",
      "\t\t\t\t11:leaf=0.0344301052\n",
      "\t\t\t\t12:leaf=-0.322968125\n",
      "\t\t\t8:[f26<-0.377509862] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=-0.245573476\n",
      "\t\t\t\t14:[f15<-0.434716612] yes=15,no=16,missing=16\n",
      "\t\t\t\t\t15:leaf=0.352089524\n",
      "\t\t\t\t\t16:leaf=0.00129692792\n",
      "\t\t4:leaf=0.247918338\n",
      "\t2:[f6<-0.370614171] yes=5,no=6,missing=6\n",
      "\t\t5:[f1<0.0582584739] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.181766272\n",
      "\t\t\t10:leaf=0.227272019\n",
      "\t\t6:leaf=0.326815248\n",
      "\n",
      "\n",
      "Tree 7 structure:\n",
      "0:[f23<-0.00717778318] yes=1,no=2,missing=2\n",
      "\t1:[f27<0.665307522] yes=3,no=4,missing=4\n",
      "\t\t3:[f1<0.479457617] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f28<-1.47825623] yes=11,no=12,missing=12\n",
      "\t\t\t\t11:leaf=-0.0496328957\n",
      "\t\t\t\t12:leaf=-0.305032343\n",
      "\t\t\t8:[f20<-0.37879324] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=-0.208885223\n",
      "\t\t\t\t14:[f4<-0.557245433] yes=15,no=16,missing=16\n",
      "\t\t\t\t\t15:leaf=-0.0282443147\n",
      "\t\t\t\t\t16:leaf=0.261564881\n",
      "\t\t4:leaf=0.21899052\n",
      "\t2:[f6<-0.215936914] yes=5,no=6,missing=6\n",
      "\t\t5:[f1<0.0582584739] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.167173743\n",
      "\t\t\t10:leaf=0.219408557\n",
      "\t\t6:leaf=0.311111569\n",
      "\n",
      "\n",
      "Tree 8 structure:\n",
      "0:[f7<0.046967078] yes=1,no=2,missing=2\n",
      "\t1:[f3<0.124887094] yes=3,no=4,missing=4\n",
      "\t\t3:[f21<0.682767689] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f11<1.38098168] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=-0.293824047\n",
      "\t\t\t\t16:leaf=-0.0385603383\n",
      "\t\t\t8:[f26<-0.377509862] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=-0.215224266\n",
      "\t\t\t\t18:leaf=0.116172545\n",
      "\t\t4:[f1<0.0582584739] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.0591015965\n",
      "\t\t\t10:leaf=0.224432915\n",
      "\t2:[f21<-0.299180388] yes=5,no=6,missing=6\n",
      "\t\t5:[f27<0.665307522] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.184833512\n",
      "\t\t\t12:leaf=0.195286036\n",
      "\t\t6:[f7<0.181611672] yes=13,no=14,missing=14\n",
      "\t\t\t13:leaf=0.0573981442\n",
      "\t\t\t14:leaf=0.296046495\n",
      "\n",
      "\n",
      "Tree 9 structure:\n",
      "0:[f23<-0.248363405] yes=1,no=2,missing=2\n",
      "\t1:[f7<0.200441271] yes=3,no=4,missing=4\n",
      "\t\t3:[f13<-0.116764814] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f21<1.22666597] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=-0.285616636\n",
      "\t\t\t\t14:leaf=-0.0596366972\n",
      "\t\t\t8:leaf=0.0608200468\n",
      "\t\t4:leaf=0.0502758063\n",
      "\t2:[f26<-0.305546999] yes=5,no=6,missing=6\n",
      "\t\t5:[f9<-1.17769015] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=0.000639903359\n",
      "\t\t\t10:leaf=-0.169701532\n",
      "\t\t6:[f21<-0.986381173] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.0529496931\n",
      "\t\t\t12:[f19<0.876066446] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=0.286345661\n",
      "\t\t\t\t16:leaf=0.0875534117\n",
      "\n",
      "\n",
      "Tree 10 structure:\n",
      "0:[f27<0.561766684] yes=1,no=2,missing=2\n",
      "\t1:[f3<0.124887094] yes=3,no=4,missing=4\n",
      "\t\t3:[f21<0.682767689] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f28<-1.23720694] yes=11,no=12,missing=12\n",
      "\t\t\t\t11:leaf=-0.0370936543\n",
      "\t\t\t\t12:leaf=-0.280999571\n",
      "\t\t\t8:[f27<-0.412735552] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=-0.190800413\n",
      "\t\t\t\t14:[f15<-0.434716612] yes=15,no=16,missing=16\n",
      "\t\t\t\t\t15:leaf=0.242177397\n",
      "\t\t\t\t\t16:leaf=-0.0582808629\n",
      "\t\t4:[f1<0.0582584739] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.0661814287\n",
      "\t\t\t10:leaf=0.235943228\n",
      "\t2:[f23<-0.237464353] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=0.074897103\n",
      "\t\t6:leaf=0.269097894\n",
      "\n",
      "\n",
      "Tree 11 structure:\n",
      "0:[f27<0.414068699] yes=1,no=2,missing=2\n",
      "\t1:[f3<0.124887094] yes=3,no=4,missing=4\n",
      "\t\t3:[f18<-0.376832485] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f15<-0.751610279] yes=11,no=12,missing=12\n",
      "\t\t\t\t11:leaf=0.107676633\n",
      "\t\t\t\t12:leaf=-0.15529564\n",
      "\t\t\t8:leaf=-0.271094084\n",
      "\t\t4:[f1<0.0582584739] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.0399684869\n",
      "\t\t\t10:leaf=0.198331803\n",
      "\t2:[f20<-0.192418978] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=0.00257339142\n",
      "\t\t6:leaf=0.244496301\n",
      "\n",
      "\n",
      "Tree 12 structure:\n",
      "0:[f26<-0.305546999] yes=1,no=2,missing=2\n",
      "\t1:[f13<0.0533084013] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.257945269\n",
      "\t\t4:leaf=0.0680563375\n",
      "\t2:[f23<0.151913315] yes=5,no=6,missing=6\n",
      "\t\t5:[f21<0.27565819] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f27<0.487156361] yes=9,no=10,missing=10\n",
      "\t\t\t\t9:leaf=-0.212561354\n",
      "\t\t\t\t10:leaf=-0.00672803726\n",
      "\t\t\t8:[f24<0.365214616] yes=11,no=12,missing=12\n",
      "\t\t\t\t11:leaf=0.00868128147\n",
      "\t\t\t\t12:leaf=0.237202615\n",
      "\t\t6:leaf=0.255020529\n",
      "\n",
      "\n",
      "Tree 13 structure:\n",
      "0:[f7<0.046967078] yes=1,no=2,missing=2\n",
      "\t1:[f15<-0.751610279] yes=3,no=4,missing=4\n",
      "\t\t3:[f16<-0.644364178] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.174773008\n",
      "\t\t\t8:leaf=0.213052183\n",
      "\t\t4:[f28<0.442049325] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.238446027\n",
      "\t\t\t10:leaf=-0.0145207774\n",
      "\t2:[f21<-0.299180388] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=-0.0388670787\n",
      "\t\t6:leaf=0.223735198\n",
      "\n",
      "\n",
      "Tree 14 structure:\n",
      "0:[f23<-0.00717778318] yes=1,no=2,missing=2\n",
      "\t1:[f21<0.648570478] yes=3,no=4,missing=4\n",
      "\t\t3:[f12<0.27916795] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f7<0.128476068] yes=11,no=12,missing=12\n",
      "\t\t\t\t11:leaf=-0.238839582\n",
      "\t\t\t\t12:leaf=-0.05812243\n",
      "\t\t\t8:leaf=0.0483108275\n",
      "\t\t4:[f1<1.05889738] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=0.158207014\n",
      "\t\t\t10:leaf=-0.115181491\n",
      "\t2:[f6<-0.215936914] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=-0.00604520505\n",
      "\t\t6:leaf=0.231263533\n",
      "\n",
      "\n",
      "Tree 15 structure:\n",
      "0:[f27<0.665307522] yes=1,no=2,missing=2\n",
      "\t1:[f1<0.160649434] yes=3,no=4,missing=4\n",
      "\t\t3:[f13<-0.122265242] yes=5,no=6,missing=6\n",
      "\t\t\t5:[f3<-0.0352358818] yes=9,no=10,missing=10\n",
      "\t\t\t\t9:leaf=-0.224561736\n",
      "\t\t\t\t10:leaf=-0.0590839125\n",
      "\t\t\t6:leaf=-0.00638539623\n",
      "\t\t4:[f23<-0.399016529] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.133598849\n",
      "\t\t\t8:[f5<-0.61764735] yes=11,no=12,missing=12\n",
      "\t\t\t\t11:leaf=0.211652175\n",
      "\t\t\t\t12:leaf=0.0359145962\n",
      "\t2:leaf=0.20108366\n",
      "\n",
      "\n",
      "Tree 16 structure:\n",
      "0:[f26<-0.305546999] yes=1,no=2,missing=2\n",
      "\t1:[f13<0.0533084013] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.216843292\n",
      "\t\t4:leaf=0.0493969619\n",
      "\t2:[f21<-0.0158321951] yes=5,no=6,missing=6\n",
      "\t\t5:[f0<0.233660832] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.146588027\n",
      "\t\t\t8:leaf=0.068819873\n",
      "\t\t6:[f4<-0.491061568] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=0.0142315011\n",
      "\t\t\t10:leaf=0.200916067\n",
      "\n",
      "\n",
      "Tree 17 structure:\n",
      "0:[f13<-0.198171139] yes=1,no=2,missing=2\n",
      "\t1:[f28<-0.365223199] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.198618621\n",
      "\t\t4:[f18<-0.368356973] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=0.107979089\n",
      "\t\t\t8:leaf=-0.110814892\n",
      "\t2:[f24<-0.90164268] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=-0.0538073853\n",
      "\t\t6:leaf=0.175646141\n",
      "\n",
      "\n",
      "Tree 18 structure:\n",
      "0:[f27<0.665307522] yes=1,no=2,missing=2\n",
      "\t1:[f15<-0.751610279] yes=3,no=4,missing=4\n",
      "\t\t3:[f1<0.0792020783] yes=5,no=6,missing=6\n",
      "\t\t\t5:leaf=-0.00932441372\n",
      "\t\t\t6:leaf=0.129060045\n",
      "\t\t4:[f23<-0.00717778318] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f27<0.321186453] yes=9,no=10,missing=10\n",
      "\t\t\t\t9:leaf=-0.219693586\n",
      "\t\t\t\t10:leaf=-0.033285901\n",
      "\t\t\t8:leaf=0.0362772681\n",
      "\t2:leaf=0.167072982\n",
      "\n",
      "\n",
      "Tree 19 structure:\n",
      "0:[f21<-0.431083858] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.143336162\n",
      "\t2:[f4<-0.43199423] yes=3,no=4,missing=4\n",
      "\t\t3:[f9<-0.974972785] yes=5,no=6,missing=6\n",
      "\t\t\t5:leaf=0.098094672\n",
      "\t\t\t6:leaf=-0.176664889\n",
      "\t\t4:[f13<-0.129745826] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=0.0555937365\n",
      "\t\t\t8:leaf=0.197797149\n",
      "\n",
      "\n",
      "Tree 20 structure:\n",
      "0:[f26<-0.381347865] yes=1,no=2,missing=2\n",
      "\t1:[f13<0.0533084013] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.179353386\n",
      "\t\t4:leaf=0.0154837323\n",
      "\t2:[f23<0.151913315] yes=5,no=6,missing=6\n",
      "\t\t5:[f21<0.00696593663] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.136609018\n",
      "\t\t\t8:[f7<-0.184147] yes=9,no=10,missing=10\n",
      "\t\t\t\t9:leaf=-0.0113423131\n",
      "\t\t\t\t10:leaf=0.131649882\n",
      "\t\t6:leaf=0.185033768\n",
      "\n",
      "\n",
      "Tree 21 structure:\n",
      "0:[f26<-0.305546999] yes=1,no=2,missing=2\n",
      "\t1:[f13<0.0533084013] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.171242476\n",
      "\t\t4:leaf=0.0235845428\n",
      "\t2:[f23<-0.271919429] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=-0.0463552624\n",
      "\t\t6:[f23<0.151913315] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=0.0403790325\n",
      "\t\t\t8:leaf=0.165718362\n",
      "\n",
      "\n",
      "Tree 22 structure:\n",
      "0:[f21<-0.431083858] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.117204301\n",
      "\t2:[f4<-0.43199423] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.0559649765\n",
      "\t\t4:[f13<-0.376164973] yes=5,no=6,missing=6\n",
      "\t\t\t5:leaf=0.0321135037\n",
      "\t\t\t6:leaf=0.157310024\n",
      "\n",
      "\n",
      "Tree 23 structure:\n",
      "0:[f28<-0.116085] yes=1,no=2,missing=2\n",
      "\t1:[f17<0.362354159] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.129318953\n",
      "\t\t4:leaf=0.0421832912\n",
      "\t2:[f24<0.22055617] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=-0.0213734452\n",
      "\t\t6:leaf=0.136424541\n",
      "\n",
      "\n",
      "Tree 24 structure:\n",
      "0:[f23<-0.577620447] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.1137366\n",
      "\t2:[f24<-1.05068469] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.0985461995\n",
      "\t\t4:[f13<-0.355043322] yes=5,no=6,missing=6\n",
      "\t\t\t5:leaf=0.00640364923\n",
      "\t\t\t6:leaf=0.142363012\n",
      "\n",
      "\n",
      "Tree 25 structure:\n",
      "0:[f21<0.682767689] yes=1,no=2,missing=2\n",
      "\t1:[f10<0.32529068] yes=3,no=4,missing=4\n",
      "\t\t3:[f28<-0.211534053] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.169506177\n",
      "\t\t\t8:leaf=-0.0111947823\n",
      "\t\t4:leaf=0.0758946911\n",
      "\t2:[f4<-0.543724] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=0.0133867683\n",
      "\t\t6:leaf=0.114455394\n",
      "\n",
      "\n",
      "Tree 26 structure:\n",
      "0:[f15<-0.751610279] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0980462804\n",
      "\t2:[f7<0.128476068] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.138296127\n",
      "\t\t4:leaf=0.0807231963\n",
      "\n",
      "\n",
      "Tree 27 structure:\n",
      "0:[f21<-0.431083858] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0997325853\n",
      "\t2:[f15<-0.434716612] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=0.125534356\n",
      "\t\t4:leaf=-0.0433573015\n",
      "\n",
      "\n",
      "Tree 28 structure:\n",
      "0:[f26<-0.305546999] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0858360976\n",
      "\t2:[f23<-0.271919429] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.0425944179\n",
      "\t\t4:leaf=0.108706109\n",
      "\n",
      "\n",
      "Tree 29 structure:\n",
      "0:[f3<0.124887094] yes=1,no=2,missing=2\n",
      "\t1:[f18<-0.368356973] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=0.0492164381\n",
      "\t\t4:leaf=-0.127947196\n",
      "\t2:leaf=0.0784086958\n",
      "\n",
      "\n",
      "Tree 30 structure:\n",
      "0:[f21<-0.455510437] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0903559029\n",
      "\t2:[f15<-0.434716612] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=0.105082341\n",
      "\t\t4:leaf=-0.0349093638\n",
      "\n",
      "\n",
      "Tree 31 structure:\n",
      "0:[f24<0.22055617] yes=1,no=2,missing=2\n",
      "\t1:[f9<-0.974972785] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=0.0558508374\n",
      "\t\t4:leaf=-0.113196306\n",
      "\t2:leaf=0.0773865134\n",
      "\n",
      "\n",
      "Tree 32 structure:\n",
      "0:[f26<-0.381347865] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0782778561\n",
      "\t2:[f23<-0.271919429] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.0368089788\n",
      "\t\t4:leaf=0.094010517\n",
      "\n",
      "\n",
      "Tree 33 structure:\n",
      "0:[f7<0.128476068] yes=1,no=2,missing=2\n",
      "\t1:[f5<-0.830282986] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=0.0776475146\n",
      "\t\t4:leaf=-0.117613539\n",
      "\t2:leaf=0.0714869872\n",
      "\n",
      "\n",
      "Tree 34 structure:\n",
      "0:[f21<-0.372460097] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0790516734\n",
      "\t2:[f4<-0.43199423] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.0406999066\n",
      "\t\t4:leaf=0.0971362814\n",
      "\n",
      "\n",
      "Tree 35 structure:\n",
      "0:[f23<-0.00717778318] yes=1,no=2,missing=2\n",
      "\t1:[f18<-0.368356973] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=0.0281232502\n",
      "\t\t4:leaf=-0.102828763\n",
      "\t2:leaf=0.0719714016\n",
      "\n",
      "\n",
      "Tree 36 structure:\n",
      "0:[f28<-0.116085] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0557410456\n",
      "\t2:leaf=0.0554243214\n",
      "\n",
      "\n",
      "Tree 37 structure:\n",
      "0:[f13<-0.129745826] yes=1,no=2,missing=2\n",
      "\t1:[f28<0.099079825] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.092058219\n",
      "\t\t4:leaf=0.0285899993\n",
      "\t2:leaf=0.0654808357\n",
      "\n",
      "\n",
      "Tree 38 structure:\n",
      "0:[f1<0.211844906] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0500653349\n",
      "\t2:leaf=0.0538080074\n",
      "\n",
      "\n",
      "Tree 39 structure:\n",
      "0:[f26<-0.305546999] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0620530024\n",
      "\t2:[f9<-0.284599572] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=0.0871896744\n",
      "\t\t4:leaf=-0.0151442625\n",
      "\n",
      "\n",
      "Tree 40 structure:\n",
      "0:[f13<-0.129745826] yes=1,no=2,missing=2\n",
      "\t1:[f24<0.18110387] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.0885428414\n",
      "\t\t4:leaf=0.0291042626\n",
      "\t2:leaf=0.0606373213\n",
      "\n",
      "\n",
      "Tree 41 structure:\n",
      "0:[f5<-0.76963824] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.060820885\n",
      "\t2:[f7<0.128476068] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.102546625\n",
      "\t\t4:leaf=0.0579612479\n",
      "\n",
      "\n",
      "Tree 42 structure:\n",
      "0:[f26<-0.305546999] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0559408516\n",
      "\t2:[f21<0.27565819] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.0179880485\n",
      "\t\t4:leaf=0.0783373564\n",
      "\n",
      "\n",
      "Tree 43 structure:\n",
      "0:[f13<-0.343602449] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0513207875\n",
      "\t2:leaf=0.0450436436\n",
      "\n",
      "\n",
      "Tree 44 structure:\n",
      "0:[f15<-0.434716612] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0492742211\n",
      "\t2:leaf=-0.0442674421\n",
      "\n",
      "\n",
      "Tree 45 structure:\n",
      "0:[f4<-0.541589022] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0539910011\n",
      "\t2:leaf=0.0426105\n",
      "\n",
      "\n",
      "Tree 46 structure:\n",
      "0:[f3<0.124887094] yes=1,no=2,missing=2\n",
      "\t1:[f18<-0.368356973] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=0.032369446\n",
      "\t\t4:leaf=-0.0909521133\n",
      "\t2:leaf=0.05605416\n",
      "\n",
      "\n",
      "Tree 47 structure:\n",
      "0:[f26<-0.305546999] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0556640513\n",
      "\t2:[f24<0.128500789] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.0160568133\n",
      "\t\t4:leaf=0.0738222003\n",
      "\n",
      "\n",
      "Tree 48 structure:\n",
      "0:[f13<-0.343602449] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0479991995\n",
      "\t2:leaf=0.0405329615\n",
      "\n",
      "\n",
      "Tree 49 structure:\n",
      "0:[f1<0.211844906] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0437389761\n",
      "\t2:leaf=0.0472719334\n",
      "\n",
      "\n",
      "Tree 50 structure:\n",
      "0:[f5<-0.61764735] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0514932983\n",
      "\t2:leaf=-0.0361449718\n",
      "\n",
      "\n",
      "Tree 51 structure:\n",
      "0:[f26<-0.305546999] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.053025879\n",
      "\t2:leaf=0.0381238349\n",
      "\n",
      "\n",
      "Tree 52 structure:\n",
      "0:[f3<0.124887094] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0342081524\n",
      "\t2:leaf=0.0501748286\n",
      "\n",
      "\n",
      "Tree 53 structure:\n",
      "0:[f28<0.099079825] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0361814499\n",
      "\t2:leaf=0.0477781557\n",
      "\n",
      "\n",
      "Tree 54 structure:\n",
      "0:[f15<-0.434716612] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0456067771\n",
      "\t2:leaf=-0.0395582691\n",
      "\n",
      "\n",
      "Tree 55 structure:\n",
      "0:[f17<0.149859488] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.037522316\n",
      "\t2:leaf=0.0490888134\n",
      "\n",
      "\n",
      "Tree 56 structure:\n",
      "0:[f4<-0.541589022] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0436265469\n",
      "\t2:leaf=0.0363825187\n",
      "\n",
      "\n",
      "Tree 57 structure:\n",
      "0:[f5<-0.61764735] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0495718233\n",
      "\t2:leaf=-0.0335553549\n",
      "\n",
      "\n",
      "Tree 58 structure:\n",
      "0:[f23<-0.267700434] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0421493687\n",
      "\t2:leaf=0.0397242196\n",
      "\n",
      "\n",
      "Tree 59 structure:\n",
      "0:[f24<0.172336683] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0322096907\n",
      "\t2:leaf=0.047561381\n",
      "\n",
      "\n",
      "Tree 60 structure:\n",
      "0:[f13<-0.343602449] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0415131077\n",
      "\t2:leaf=0.0381338224\n",
      "\n",
      "\n",
      "Tree 61 structure:\n",
      "0:[f15<-0.434716612] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0421703346\n",
      "\t2:leaf=-0.037695013\n",
      "\n",
      "\n",
      "Tree 62 structure:\n",
      "0:[f28<-0.365223199] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0430599339\n",
      "\t2:leaf=0.035679955\n",
      "\n",
      "\n",
      "Tree 63 structure:\n",
      "0:[f1<0.211844906] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0355961658\n",
      "\t2:leaf=0.0405078456\n",
      "\n",
      "\n",
      "Tree 64 structure:\n",
      "0:[f17<0.149859488] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0347378589\n",
      "\t2:leaf=0.0436978489\n",
      "\n",
      "\n",
      "Tree 65 structure:\n",
      "0:[f23<-0.267700434] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0374743268\n",
      "\t2:leaf=0.0347522534\n",
      "\n",
      "\n",
      "Tree 66 structure:\n",
      "0:[f15<-0.434716612] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0380022526\n",
      "\t2:leaf=-0.0349395499\n",
      "\n",
      "\n",
      "Tree 67 structure:\n",
      "0:[f4<-0.541589022] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0421463996\n",
      "\t2:leaf=0.0332253352\n",
      "\n",
      "\n",
      "Tree 68 structure:\n",
      "0:[f17<0.219609648] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0308711939\n",
      "\t2:leaf=0.0399072208\n",
      "\n",
      "\n",
      "Tree 69 structure:\n",
      "0:[f1<0.211844906] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0322252885\n",
      "\t2:leaf=0.0375530645\n",
      "\n",
      "\n",
      "Tree 70 structure:\n",
      "0:[f23<-0.267700434] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.036220815\n",
      "\t2:leaf=0.0331280194\n",
      "\n",
      "\n",
      "Tree 71 structure:\n",
      "0:[f15<-0.434716612] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0355598554\n",
      "\t2:leaf=-0.0330601186\n",
      "\n",
      "\n",
      "Tree 72 structure:\n",
      "0:[f17<0.219609648] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0297503956\n",
      "\t2:leaf=0.0396409854\n",
      "\n",
      "\n",
      "Tree 73 structure:\n",
      "0:[f28<-0.365223199] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0377624072\n",
      "\t2:leaf=0.0307745636\n",
      "\n",
      "\n",
      "Tree 74 structure:\n",
      "0:[f18<-0.310239315] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0320204645\n",
      "\t2:leaf=-0.0380781442\n",
      "\n",
      "\n",
      "Tree 75 structure:\n",
      "0:[f13<-0.343602449] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0381697863\n",
      "\t2:leaf=0.0316270776\n",
      "\n",
      "\n",
      "Tree 76 structure:\n",
      "0:[f14<-0.524680912] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.03743295\n",
      "\t2:leaf=0.0280855261\n",
      "\n",
      "\n",
      "Tree 77 structure:\n",
      "0:[f28<0.099079825] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0302993078\n",
      "\t2:leaf=0.0348264948\n",
      "\n",
      "\n",
      "Tree 78 structure:\n",
      "0:[f18<-0.310239315] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0305257905\n",
      "\t2:leaf=-0.0373318121\n",
      "\n",
      "\n",
      "Tree 79 structure:\n",
      "0:[f1<0.211844906] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0293932352\n",
      "\t2:leaf=0.0321063437\n",
      "\n",
      "\n",
      "Tree 80 structure:\n",
      "0:[f13<-0.343602449] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0342799164\n",
      "\t2:leaf=0.028214328\n",
      "\n",
      "\n",
      "Tree 81 structure:\n",
      "0:[f15<-0.434716612] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0309224464\n",
      "\t2:leaf=-0.0306481533\n",
      "\n",
      "\n",
      "Tree 82 structure:\n",
      "0:[f6<-0.199238807] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0316751264\n",
      "\t2:leaf=0.0345458053\n",
      "\n",
      "\n",
      "Tree 83 structure:\n",
      "0:[f15<-0.58226496] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0331425928\n",
      "\t2:leaf=-0.0273277108\n",
      "\n",
      "\n",
      "Tree 84 structure:\n",
      "0:[f6<-0.199238807] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0292262174\n",
      "\t2:leaf=0.0331498198\n",
      "\n",
      "\n",
      "Tree 85 structure:\n",
      "0:[f18<-0.310239315] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0280081425\n",
      "\t2:leaf=-0.0322197191\n",
      "\n",
      "\n",
      "Tree 86 structure:\n",
      "0:[f28<-0.116085] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0303764008\n",
      "\t2:leaf=0.0303323567\n",
      "\n",
      "\n",
      "Tree 87 structure:\n",
      "0:[f23<-0.267700434] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0319712646\n",
      "\t2:leaf=0.02811414\n",
      "\n",
      "\n",
      "Tree 88 structure:\n",
      "0:[f17<0.144993201] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0267811343\n",
      "\t2:leaf=0.0313547328\n",
      "\n",
      "\n",
      "Tree 89 structure:\n",
      "0:[f15<-0.434716612] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0311889667\n",
      "\t2:leaf=-0.0296362042\n",
      "\n",
      "\n",
      "Tree 90 structure:\n",
      "0:[f21<0.00859437417] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0312361475\n",
      "\t2:leaf=0.0279977191\n",
      "\n",
      "\n",
      "Tree 91 structure:\n",
      "0:[f19<-0.441004694] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0319347791\n",
      "\t2:leaf=0.0268508326\n",
      "\n",
      "\n",
      "Tree 92 structure:\n",
      "0:[f23<-0.267700434] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0304989051\n",
      "\t2:leaf=0.0259472672\n",
      "\n",
      "\n",
      "Tree 93 structure:\n",
      "0:[f15<-0.434716612] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0284111053\n",
      "\t2:leaf=-0.0284803063\n",
      "\n",
      "\n",
      "Tree 94 structure:\n",
      "0:[f6<-0.199238807] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0274640229\n",
      "\t2:leaf=0.02975755\n",
      "\n",
      "\n",
      "Tree 95 structure:\n",
      "0:[f18<-0.318714797] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0254844353\n",
      "\t2:leaf=-0.030204555\n",
      "\n",
      "\n",
      "Tree 96 structure:\n",
      "0:[f28<-0.116085] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.027390616\n",
      "\t2:leaf=0.0263976324\n",
      "\n",
      "\n",
      "Tree 97 structure:\n",
      "0:[f15<-0.434716612] yes=1,no=2,missing=2\n",
      "\t1:leaf=0.0262494218\n",
      "\t2:leaf=-0.0260337535\n",
      "\n",
      "\n",
      "Tree 98 structure:\n",
      "0:[f6<-0.199238807] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0264220964\n",
      "\t2:leaf=0.0289052203\n",
      "\n",
      "\n",
      "Tree 99 structure:\n",
      "0:[f13<-0.243934691] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0238732155\n",
      "\t2:leaf=0.0274038594\n",
      "\n",
      "\n",
      "Tree 100 structure:\n",
      "0:[f21<0.00859437417] yes=1,no=2,missing=2\n",
      "\t1:leaf=-0.0278796703\n",
      "\t2:leaf=0.0253321659\n",
      "\n",
      "\n",
      "Model Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data from a CSV file\n",
    "data = np.genfromtxt('breast+cancer+wisconsin+diagnostic/wdbc.data', delimiter=',', dtype=str)\n",
    "\n",
    "# Extract features and convert them to float for numerical operations\n",
    "X = data[:, 2:].astype(float)  # Features start from the 3rd column (index 2)\n",
    "\n",
    "# Convert labels from 'M' (Malignant) and 'B' (Benign) to binary (1 and 0)\n",
    "y = np.where(data[:, 1] == 'M', 1, 0)\n",
    "\n",
    "# Normalize the features by subtracting the mean and dividing by the standard deviation\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBoost model with log loss as the evaluation metric\n",
    "model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Fits the XGBoost model to the training data.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve and print model parameters for reference\n",
    "params = model.get_params()\n",
    "n_estimators = params['n_estimators']\n",
    "max_depth = params['max_depth']\n",
    "learning_rate = params['learning_rate']\n",
    "\n",
    "print(\"Number of estimators:\", n_estimators)\n",
    "print(\"Max depth:\", max_depth)\n",
    "print(\"Learning rate:\", learning_rate)\n",
    "\n",
    "# Retrieve the trained booster (underlying model) from XGBoost\n",
    "booster = model.get_booster()\n",
    "\n",
    "# Iterate over each tree in the model and print its structure\n",
    "for i, tree in enumerate(booster.get_dump()):\n",
    "    print(f\"Tree {i + 1} structure:\\n{tree}\\n\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute and print the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2060",
   "language": "python",
   "name": "data2060"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
